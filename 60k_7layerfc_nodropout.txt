Script started on Fri 01 Jun 2018 04:00:48 PM CDT
]0;sid@blueberry: ~/rddnn[01;32msid@blueberry[00m:[01;34m~/rddnn[00m$ exitpython cifar_train.py 
/home/sid/python3_tf/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Going to read training images
Now going to read airplane files (Index: 0)
Now going to read automobile files (Index: 1)
Now going to read bird files (Index: 2)
Now going to read cat files (Index: 3)
Now going to read deer files (Index: 4)
Now going to read dog files (Index: 5)
Now going to read frog files (Index: 6)
Now going to read horse files (Index: 7)
Now going to read ship files (Index: 8)
Now going to read truck files (Index: 9)
Going to read training images
Now going to read airplane files (Index: 0)
Now going to read automobile files (Index: 1)
Now going to read bird files (Index: 2)
Now going to read cat files (Index: 3)
Now going to read deer files (Index: 4)
Now going to read dog files (Index: 5)
Now going to read frog files (Index: 6)
Now going to read horse files (Index: 7)
Now going to read ship files (Index: 8)
Now going to read truck files (Index: 9)
Complete reading input data. Will Now print a snippet of it
Number of files in Training-set:		50000
Number of files in Validation-set:	10000
2018-06-01 16:00:56.790216: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-06-01 16:00:56.864357: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-06-01 16:00:56.864553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: GeForce GTX 1060 6GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:01:00.0
totalMemory: 5.93GiB freeMemory: 5.65GiB
2018-06-01 16:00:56.864565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1)
WARNING:tensorflow:From cifar_train.py:41: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.
Instructions for updating:
Use the `axis` argument instead
WARNING:tensorflow:From cifar_train.py:198: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See tf.nn.softmax_cross_entropy_with_logits_v2.

Training Epoch 1 --- Training Accuracy:  12.9%, Validation Accuracy:  11.2%,  Validation Loss: 2.299
0
Training Epoch 2 --- Training Accuracy:  32.0%, Validation Accuracy:  31.1%,  Validation Loss: 2.026
195
Training Epoch 3 --- Training Accuracy:  37.1%, Validation Accuracy:  36.8%,  Validation Loss: 1.962
390
Training Epoch 4 --- Training Accuracy:  39.5%, Validation Accuracy:  37.3%,  Validation Loss: 1.947
585
Training Epoch 5 --- Training Accuracy:  41.4%, Validation Accuracy:  39.3%,  Validation Loss: 1.934
780
Training Epoch 6 --- Training Accuracy:  45.3%, Validation Accuracy:  39.9%,  Validation Loss: 1.931
975
Training Epoch 7 --- Training Accuracy:  46.9%, Validation Accuracy:  42.5%,  Validation Loss: 1.922
1170
Training Epoch 8 --- Training Accuracy:  48.4%, Validation Accuracy:  43.4%,  Validation Loss: 1.904
1365
Training Epoch 9 --- Training Accuracy:  50.8%, Validation Accuracy:  43.9%,  Validation Loss: 1.897
1560
Training Epoch 10 --- Training Accuracy:  47.3%, Validation Accuracy:  43.7%,  Validation Loss: 1.893
1755
Training Epoch 11 --- Training Accuracy:  48.0%, Validation Accuracy:  43.1%,  Validation Loss: 1.894
1950
Training Epoch 12 --- Training Accuracy:  50.8%, Validation Accuracy:  44.9%,  Validation Loss: 1.881
2145
Training Epoch 13 --- Training Accuracy:  51.6%, Validation Accuracy:  44.7%,  Validation Loss: 1.881
2340
Training Epoch 14 --- Training Accuracy:  53.1%, Validation Accuracy:  43.7%,  Validation Loss: 1.883
2535
Training Epoch 15 --- Training Accuracy:  52.0%, Validation Accuracy:  44.7%,  Validation Loss: 1.878
2730
Training Epoch 16 --- Training Accuracy:  51.2%, Validation Accuracy:  46.0%,  Validation Loss: 1.877
2925
Training Epoch 17 --- Training Accuracy:  55.5%, Validation Accuracy:  45.4%,  Validation Loss: 1.872
3120
Training Epoch 18 --- Training Accuracy:  52.0%, Validation Accuracy:  43.3%,  Validation Loss: 1.908
3315
Training Epoch 19 --- Training Accuracy:  53.1%, Validation Accuracy:  42.7%,  Validation Loss: 1.903
3510
Training Epoch 20 --- Training Accuracy:  56.6%, Validation Accuracy:  45.1%,  Validation Loss: 1.886
3705
Training Epoch 21 --- Training Accuracy:  60.2%, Validation Accuracy:  46.6%,  Validation Loss: 1.867
3900
Training Epoch 22 --- Training Accuracy:  62.1%, Validation Accuracy:  46.1%,  Validation Loss: 1.867
4095
Training Epoch 23 --- Training Accuracy:  60.5%, Validation Accuracy:  45.4%,  Validation Loss: 1.868
4290
Training Epoch 24 --- Training Accuracy:  61.7%, Validation Accuracy:  47.7%,  Validation Loss: 1.868
4485
Training Epoch 25 --- Training Accuracy:  60.2%, Validation Accuracy:  45.9%,  Validation Loss: 1.867
4680
Training Epoch 26 --- Training Accuracy:  60.9%, Validation Accuracy:  44.9%,  Validation Loss: 1.877
4875
Training Epoch 27 --- Training Accuracy:  59.4%, Validation Accuracy:  46.2%,  Validation Loss: 1.868
5070
Training Epoch 28 --- Training Accuracy:  60.2%, Validation Accuracy:  45.5%,  Validation Loss: 1.861
5265
Training Epoch 29 --- Training Accuracy:  61.3%, Validation Accuracy:  47.9%,  Validation Loss: 1.864
5460
Training Epoch 30 --- Training Accuracy:  63.7%, Validation Accuracy:  48.4%,  Validation Loss: 1.856
5655
Training Epoch 31 --- Training Accuracy:  59.4%, Validation Accuracy:  49.3%,  Validation Loss: 1.869
5850
Training Epoch 32 --- Training Accuracy:  62.9%, Validation Accuracy:  48.0%,  Validation Loss: 1.870
6045
Training Epoch 33 --- Training Accuracy:  61.3%, Validation Accuracy:  48.4%,  Validation Loss: 1.879
6240
Training Epoch 34 --- Training Accuracy:  62.1%, Validation Accuracy:  49.3%,  Validation Loss: 1.876
6435
Training Epoch 35 --- Training Accuracy:  63.7%, Validation Accuracy:  49.3%,  Validation Loss: 1.868
6630
Training Epoch 36 --- Training Accuracy:  64.8%, Validation Accuracy:  48.8%,  Validation Loss: 1.867
6825
Training Epoch 37 --- Training Accuracy:  65.2%, Validation Accuracy:  49.7%,  Validation Loss: 1.868
7020
Training Epoch 38 --- Training Accuracy:  64.5%, Validation Accuracy:  50.1%,  Validation Loss: 1.874
7215
Training Epoch 39 --- Training Accuracy:  66.4%, Validation Accuracy:  50.2%,  Validation Loss: 1.882
7410
Training Epoch 40 --- Training Accuracy:  68.0%, Validation Accuracy:  50.8%,  Validation Loss: 1.866
7605
Training Epoch 41 --- Training Accuracy:  66.8%, Validation Accuracy:  49.0%,  Validation Loss: 1.868
7800
Training Epoch 42 --- Training Accuracy:  68.0%, Validation Accuracy:  50.3%,  Validation Loss: 1.876
7995
Training Epoch 43 --- Training Accuracy:  69.9%, Validation Accuracy:  50.2%,  Validation Loss: 1.884
8190
Training Epoch 44 --- Training Accuracy:  71.5%, Validation Accuracy:  50.2%,  Validation Loss: 1.872
8385
Training Epoch 45 --- Training Accuracy:  67.2%, Validation Accuracy:  50.5%,  Validation Loss: 1.861
8580
Training Epoch 46 --- Training Accuracy:  74.6%, Validation Accuracy:  50.4%,  Validation Loss: 1.866
8775
Training Epoch 47 --- Training Accuracy:  69.1%, Validation Accuracy:  50.2%,  Validation Loss: 1.861
8970
Training Epoch 48 --- Training Accuracy:  71.5%, Validation Accuracy:  49.3%,  Validation Loss: 1.874
9165
Training Epoch 49 --- Training Accuracy:  73.4%, Validation Accuracy:  51.1%,  Validation Loss: 1.871
9360
Training Epoch 50 --- Training Accuracy:  72.7%, Validation Accuracy:  50.6%,  Validation Loss: 1.872
9555
Training Epoch 51 --- Training Accuracy:  71.9%, Validation Accuracy:  49.8%,  Validation Loss: 1.882
9750
Training Epoch 52 --- Training Accuracy:  72.7%, Validation Accuracy:  51.0%,  Validation Loss: 1.870
9945
Training Epoch 53 --- Training Accuracy:  71.9%, Validation Accuracy:  49.9%,  Validation Loss: 1.880
10140
Training Epoch 54 --- Training Accuracy:  70.7%, Validation Accuracy:  49.8%,  Validation Loss: 1.881
10335
Training Epoch 55 --- Training Accuracy:  75.8%, Validation Accuracy:  50.6%,  Validation Loss: 1.877
10530
Training Epoch 56 --- Training Accuracy:  74.2%, Validation Accuracy:  50.7%,  Validation Loss: 1.872
10725
Training Epoch 57 --- Training Accuracy:  74.6%, Validation Accuracy:  50.2%,  Validation Loss: 1.880
10920
Training Epoch 58 --- Training Accuracy:  73.0%, Validation Accuracy:  50.0%,  Validation Loss: 1.878
11115
Training Epoch 59 --- Training Accuracy:  75.0%, Validation Accuracy:  50.3%,  Validation Loss: 1.891
11310
Training Epoch 60 --- Training Accuracy:  70.3%, Validation Accuracy:  50.2%,  Validation Loss: 1.873
11505
Training Epoch 61 --- Training Accuracy:  76.2%, Validation Accuracy:  50.6%,  Validation Loss: 1.873
11700
Training Epoch 62 --- Training Accuracy:  76.2%, Validation Accuracy:  50.2%,  Validation Loss: 1.868
11895
Training Epoch 63 --- Training Accuracy:  77.7%, Validation Accuracy:  51.3%,  Validation Loss: 1.884
12090
Training Epoch 64 --- Training Accuracy:  75.4%, Validation Accuracy:  50.0%,  Validation Loss: 1.887
12285
Training Epoch 65 --- Training Accuracy:  76.6%, Validation Accuracy:  51.2%,  Validation Loss: 1.875
12480
Training Epoch 66 --- Training Accuracy:  77.7%, Validation Accuracy:  51.6%,  Validation Loss: 1.871
12675
Training Epoch 67 --- Training Accuracy:  77.3%, Validation Accuracy:  50.9%,  Validation Loss: 1.881
12870
Training Epoch 68 --- Training Accuracy:  79.3%, Validation Accuracy:  50.6%,  Validation Loss: 1.885
13065
Training Epoch 69 --- Training Accuracy:  78.1%, Validation Accuracy:  50.6%,  Validation Loss: 1.872
13260
Training Epoch 70 --- Training Accuracy:  79.7%, Validation Accuracy:  50.2%,  Validation Loss: 1.884
13455
Training Epoch 71 --- Training Accuracy:  79.3%, Validation Accuracy:  50.2%,  Validation Loss: 1.885
13650
Training Epoch 72 --- Training Accuracy:  80.5%, Validation Accuracy:  50.5%,  Validation Loss: 1.877
13845
Training Epoch 73 --- Training Accuracy:  82.0%, Validation Accuracy:  49.8%,  Validation Loss: 1.879
14040
Training Epoch 74 --- Training Accuracy:  78.9%, Validation Accuracy:  50.4%,  Validation Loss: 1.881
14235
Training Epoch 75 --- Training Accuracy:  81.2%, Validation Accuracy:  50.0%,  Validation Loss: 1.885
14430
Training Epoch 76 --- Training Accuracy:  81.6%, Validation Accuracy:  50.1%,  Validation Loss: 1.884
14625
Training Epoch 77 --- Training Accuracy:  78.9%, Validation Accuracy:  51.3%,  Validation Loss: 1.881
14820
Training Epoch 78 --- Training Accuracy:  81.2%, Validation Accuracy:  50.8%,  Validation Loss: 1.878
15015
Training Epoch 79 --- Training Accuracy:  81.6%, Validation Accuracy:  50.8%,  Validation Loss: 1.884
15210
Training Epoch 80 --- Training Accuracy:  83.6%, Validation Accuracy:  50.9%,  Validation Loss: 1.886
15405
Training Epoch 81 --- Training Accuracy:  84.0%, Validation Accuracy:  50.0%,  Validation Loss: 1.894
15600
Training Epoch 82 --- Training Accuracy:  81.6%, Validation Accuracy:  52.1%,  Validation Loss: 1.875
15795
Training Epoch 83 --- Training Accuracy:  80.5%, Validation Accuracy:  51.6%,  Validation Loss: 1.883
15990
Training Epoch 84 --- Training Accuracy:  84.4%, Validation Accuracy:  50.7%,  Validation Loss: 1.890
16185
Training Epoch 85 --- Training Accuracy:  83.6%, Validation Accuracy:  51.3%,  Validation Loss: 1.892
16380
Training Epoch 86 --- Training Accuracy:  85.5%, Validation Accuracy:  52.1%,  Validation Loss: 1.887
16575
Training Epoch 87 --- Training Accuracy:  86.7%, Validation Accuracy:  50.5%,  Validation Loss: 1.889
16770
Training Epoch 88 --- Training Accuracy:  86.3%, Validation Accuracy:  52.5%,  Validation Loss: 1.884
16965
Training Epoch 89 --- Training Accuracy:  84.4%, Validation Accuracy:  52.4%,  Validation Loss: 1.886
17160
Training Epoch 90 --- Training Accuracy:  82.0%, Validation Accuracy:  51.2%,  Validation Loss: 1.899
17355
Training Epoch 91 --- Training Accuracy:  86.3%, Validation Accuracy:  51.7%,  Validation Loss: 1.878
17550
Training Epoch 92 --- Training Accuracy:  86.3%, Validation Accuracy:  53.0%,  Validation Loss: 1.881
17745
Training Epoch 93 --- Training Accuracy:  86.3%, Validation Accuracy:  51.7%,  Validation Loss: 1.889
17940
Training Epoch 94 --- Training Accuracy:  85.9%, Validation Accuracy:  51.8%,  Validation Loss: 1.890
18135
Training Epoch 95 --- Training Accuracy:  84.4%, Validation Accuracy:  51.2%,  Validation Loss: 1.902
18330
Training Epoch 96 --- Training Accuracy:  87.5%, Validation Accuracy:  52.5%,  Validation Loss: 1.879
18525
Training Epoch 97 --- Training Accuracy:  84.4%, Validation Accuracy:  50.8%,  Validation Loss: 1.889
18720
Training Epoch 98 --- Training Accuracy:  85.2%, Validation Accuracy:  52.1%,  Validation Loss: 1.888
18915
Training Epoch 99 --- Training Accuracy:  87.5%, Validation Accuracy:  51.9%,  Validation Loss: 1.897
19110
Training Epoch 100 --- Training Accuracy:  85.9%, Validation Accuracy:  52.5%,  Validation Loss: 1.879
19305
Training Epoch 101 --- Training Accuracy:  87.5%, Validation Accuracy:  51.7%,  Validation Loss: 1.891
19500
Training Epoch 102 --- Training Accuracy:  87.5%, Validation Accuracy:  52.6%,  Validation Loss: 1.895
19695
Training Epoch 103 --- Training Accuracy:  84.0%, Validation Accuracy:  51.7%,  Validation Loss: 1.895
19890
Training Epoch 104 --- Training Accuracy:  87.5%, Validation Accuracy:  52.1%,  Validation Loss: 1.885
20085
Training Epoch 105 --- Training Accuracy:  88.7%, Validation Accuracy:  53.0%,  Validation Loss: 1.884
20280
Training Epoch 106 --- Training Accuracy:  85.5%, Validation Accuracy:  52.1%,  Validation Loss: 1.884
20475
Training Epoch 107 --- Training Accuracy:  85.9%, Validation Accuracy:  52.1%,  Validation Loss: 1.894
20670
Training Epoch 108 --- Training Accuracy:  84.8%, Validation Accuracy:  52.1%,  Validation Loss: 1.894
20865
Training Epoch 109 --- Training Accuracy:  87.9%, Validation Accuracy:  52.1%,  Validation Loss: 1.900
21060
Training Epoch 110 --- Training Accuracy:  87.9%, Validation Accuracy:  52.3%,  Validation Loss: 1.887
21255
Training Epoch 111 --- Training Accuracy:  86.3%, Validation Accuracy:  52.2%,  Validation Loss: 1.889
21450
Training Epoch 112 --- Training Accuracy:  86.3%, Validation Accuracy:  51.8%,  Validation Loss: 1.896
21645
Training Epoch 113 --- Training Accuracy:  87.5%, Validation Accuracy:  52.1%,  Validation Loss: 1.896
21840
Training Epoch 114 --- Training Accuracy:  89.8%, Validation Accuracy:  50.7%,  Validation Loss: 1.903
22035
Training Epoch 115 --- Training Accuracy:  89.1%, Validation Accuracy:  52.3%,  Validation Loss: 1.891
22230
Training Epoch 116 --- Training Accuracy:  87.5%, Validation Accuracy:  52.0%,  Validation Loss: 1.889
22425
Training Epoch 117 --- Training Accuracy:  86.3%, Validation Accuracy:  52.1%,  Validation Loss: 1.905
22620
Training Epoch 118 --- Training Accuracy:  88.3%, Validation Accuracy:  52.2%,  Validation Loss: 1.902
22815
Training Epoch 119 --- Training Accuracy:  89.1%, Validation Accuracy:  51.6%,  Validation Loss: 1.899
23010
Training Epoch 120 --- Training Accuracy:  89.5%, Validation Accuracy:  51.0%,  Validation Loss: 1.908
23205
Training Epoch 121 --- Training Accuracy:  91.0%, Validation Accuracy:  50.8%,  Validation Loss: 1.902
23400
Training Epoch 122 --- Training Accuracy:  91.0%, Validation Accuracy:  52.5%,  Validation Loss: 1.892
23595
Training Epoch 123 --- Training Accuracy:  88.7%, Validation Accuracy:  51.2%,  Validation Loss: 1.903
23790
Training Epoch 124 --- Training Accuracy:  88.7%, Validation Accuracy:  51.8%,  Validation Loss: 1.897
23985
Training Epoch 125 --- Training Accuracy:  90.2%, Validation Accuracy:  52.1%,  Validation Loss: 1.902
24180
Training Epoch 126 --- Training Accuracy:  88.7%, Validation Accuracy:  51.6%,  Validation Loss: 1.899
24375
Training Epoch 127 --- Training Accuracy:  89.5%, Validation Accuracy:  50.2%,  Validation Loss: 1.906
24570
Training Epoch 128 --- Training Accuracy:  90.6%, Validation Accuracy:  51.6%,  Validation Loss: 1.906
24765
Training Epoch 129 --- Training Accuracy:  89.8%, Validation Accuracy:  51.0%,  Validation Loss: 1.909
24960
Training Epoch 130 --- Training Accuracy:  90.6%, Validation Accuracy:  50.8%,  Validation Loss: 1.906
25155
Training Epoch 131 --- Training Accuracy:  91.8%, Validation Accuracy:  51.3%,  Validation Loss: 1.908
25350
Training Epoch 132 --- Training Accuracy:  92.2%, Validation Accuracy:  52.5%,  Validation Loss: 1.900
25545
Training Epoch 133 --- Training Accuracy:  91.8%, Validation Accuracy:  51.7%,  Validation Loss: 1.903
25740
Training Epoch 134 --- Training Accuracy:  90.2%, Validation Accuracy:  51.8%,  Validation Loss: 1.901
25935
Training Epoch 135 --- Training Accuracy:  89.8%, Validation Accuracy:  51.1%,  Validation Loss: 1.916
26130
Training Epoch 136 --- Training Accuracy:  92.2%, Validation Accuracy:  52.1%,  Validation Loss: 1.897
26325
Training Epoch 137 --- Training Accuracy:  90.6%, Validation Accuracy:  52.6%,  Validation Loss: 1.901
26520
Training Epoch 138 --- Training Accuracy:  91.8%, Validation Accuracy:  51.9%,  Validation Loss: 1.908
26715
Training Epoch 139 --- Training Accuracy:  92.6%, Validation Accuracy:  51.2%,  Validation Loss: 1.910
26910
Training Epoch 140 --- Training Accuracy:  93.0%, Validation Accuracy:  52.2%,  Validation Loss: 1.899
27105
Training Epoch 141 --- Training Accuracy:  94.5%, Validation Accuracy:  53.0%,  Validation Loss: 1.887
27300
Training Epoch 142 --- Training Accuracy:  91.0%, Validation Accuracy:  52.6%,  Validation Loss: 1.900
27495
Training Epoch 143 --- Training Accuracy:  91.8%, Validation Accuracy:  51.2%,  Validation Loss: 1.905
27690
Training Epoch 144 --- Training Accuracy:  91.4%, Validation Accuracy:  50.8%,  Validation Loss: 1.909
27885
Training Epoch 145 --- Training Accuracy:  93.0%, Validation Accuracy:  51.0%,  Validation Loss: 1.904
28080
Training Epoch 146 --- Training Accuracy:  92.2%, Validation Accuracy:  52.5%,  Validation Loss: 1.905
28275
Training Epoch 147 --- Training Accuracy:  92.6%, Validation Accuracy:  51.6%,  Validation Loss: 1.900
28470
Training Epoch 148 --- Training Accuracy:  94.1%, Validation Accuracy:  50.7%,  Validation Loss: 1.915
28665
Training Epoch 149 --- Training Accuracy:  91.4%, Validation Accuracy:  50.8%,  Validation Loss: 1.916
28860
Training Epoch 150 --- Training Accuracy:  93.0%, Validation Accuracy:  51.8%,  Validation Loss: 1.906
29055
Training Epoch 151 --- Training Accuracy:  92.6%, Validation Accuracy:  52.3%,  Validation Loss: 1.894
29250
Training Epoch 152 --- Training Accuracy:  94.5%, Validation Accuracy:  52.0%,  Validation Loss: 1.897
29445
Training Epoch 153 --- Training Accuracy:  93.8%, Validation Accuracy:  52.2%,  Validation Loss: 1.895
29640
Training Epoch 154 --- Training Accuracy:  94.5%, Validation Accuracy:  51.3%,  Validation Loss: 1.904
29835
Training Epoch 155 --- Training Accuracy:  93.8%, Validation Accuracy:  52.3%,  Validation Loss: 1.899
30030
Training Epoch 156 --- Training Accuracy:  94.1%, Validation Accuracy:  51.2%,  Validation Loss: 1.910
30225
Training Epoch 157 --- Training Accuracy:  94.1%, Validation Accuracy:  51.8%,  Validation Loss: 1.906
30420
Training Epoch 158 --- Training Accuracy:  93.8%, Validation Accuracy:  51.8%,  Validation Loss: 1.905
30615
Training Epoch 159 --- Training Accuracy:  93.8%, Validation Accuracy:  50.8%,  Validation Loss: 1.912
30810
Training Epoch 160 --- Training Accuracy:  93.0%, Validation Accuracy:  51.6%,  Validation Loss: 1.909
31005
Training Epoch 161 --- Training Accuracy:  96.1%, Validation Accuracy:  51.3%,  Validation Loss: 1.904
31200
Training Epoch 162 --- Training Accuracy:  95.3%, Validation Accuracy:  52.1%,  Validation Loss: 1.903
31395
Training Epoch 163 --- Training Accuracy:  94.9%, Validation Accuracy:  51.6%,  Validation Loss: 1.906
31590
Training Epoch 164 --- Training Accuracy:  94.5%, Validation Accuracy:  51.1%,  Validation Loss: 1.923
31785
Training Epoch 165 --- Training Accuracy:  95.3%, Validation Accuracy:  52.5%,  Validation Loss: 1.895
31980
Training Epoch 166 --- Training Accuracy:  94.9%, Validation Accuracy:  51.9%,  Validation Loss: 1.905
32175
Training Epoch 167 --- Training Accuracy:  94.9%, Validation Accuracy:  52.0%,  Validation Loss: 1.902
32370
Training Epoch 168 --- Training Accuracy:  94.9%, Validation Accuracy:  52.6%,  Validation Loss: 1.906
32565
Training Epoch 169 --- Training Accuracy:  95.3%, Validation Accuracy:  53.0%,  Validation Loss: 1.898
32760
Training Epoch 170 --- Training Accuracy:  94.9%, Validation Accuracy:  51.6%,  Validation Loss: 1.911
32955
Training Epoch 171 --- Training Accuracy:  94.1%, Validation Accuracy:  52.4%,  Validation Loss: 1.902
33150
Training Epoch 172 --- Training Accuracy:  94.1%, Validation Accuracy:  51.2%,  Validation Loss: 1.911
33345
Training Epoch 173 --- Training Accuracy:  94.9%, Validation Accuracy:  52.1%,  Validation Loss: 1.910
33540
Training Epoch 174 --- Training Accuracy:  94.1%, Validation Accuracy:  51.2%,  Validation Loss: 1.913
33735
Training Epoch 175 --- Training Accuracy:  95.3%, Validation Accuracy:  52.0%,  Validation Loss: 1.915
33930
Training Epoch 176 --- Training Accuracy:  94.5%, Validation Accuracy:  51.1%,  Validation Loss: 1.923
34125
Training Epoch 177 --- Training Accuracy:  95.3%, Validation Accuracy:  51.5%,  Validation Loss: 1.917
34320
Training Epoch 178 --- Training Accuracy:  96.1%, Validation Accuracy:  52.0%,  Validation Loss: 1.912
34515
Training Epoch 179 --- Training Accuracy:  94.5%, Validation Accuracy:  51.9%,  Validation Loss: 1.906
34710
Training Epoch 180 --- Training Accuracy:  94.9%, Validation Accuracy:  51.7%,  Validation Loss: 1.902
34905
Training Epoch 181 --- Training Accuracy:  94.9%, Validation Accuracy:  50.6%,  Validation Loss: 1.926
35100
Training Epoch 182 --- Training Accuracy:  94.1%, Validation Accuracy:  51.6%,  Validation Loss: 1.905
35295
Training Epoch 183 --- Training Accuracy:  95.3%, Validation Accuracy:  51.2%,  Validation Loss: 1.912
35490
Training Epoch 184 --- Training Accuracy:  96.1%, Validation Accuracy:  52.5%,  Validation Loss: 1.903
35685
Training Epoch 185 --- Training Accuracy:  95.3%, Validation Accuracy:  51.8%,  Validation Loss: 1.900
35880
Training Epoch 186 --- Training Accuracy:  95.7%, Validation Accuracy:  51.9%,  Validation Loss: 1.903
36075
Training Epoch 187 --- Training Accuracy:  93.8%, Validation Accuracy:  51.9%,  Validation Loss: 1.908
36270
Training Epoch 188 --- Training Accuracy:  95.3%, Validation Accuracy:  52.7%,  Validation Loss: 1.904
36465
Training Epoch 189 --- Training Accuracy:  94.9%, Validation Accuracy:  52.2%,  Validation Loss: 1.908
36660
Training Epoch 190 --- Training Accuracy:  95.7%, Validation Accuracy:  50.7%,  Validation Loss: 1.915
36855
Training Epoch 191 --- Training Accuracy:  94.5%, Validation Accuracy:  51.5%,  Validation Loss: 1.913
37050
Training Epoch 192 --- Training Accuracy:  94.9%, Validation Accuracy:  50.6%,  Validation Loss: 1.923
37245
Training Epoch 193 --- Training Accuracy:  94.9%, Validation Accuracy:  52.6%,  Validation Loss: 1.908
37440
Training Epoch 194 --- Training Accuracy:  95.3%, Validation Accuracy:  51.8%,  Validation Loss: 1.906
37635
Training Epoch 195 --- Training Accuracy:  95.3%, Validation Accuracy:  51.9%,  Validation Loss: 1.913
37830
Training Epoch 196 --- Training Accuracy:  96.5%, Validation Accuracy:  51.1%,  Validation Loss: 1.918
38025
Training Epoch 197 --- Training Accuracy:  95.7%, Validation Accuracy:  52.5%,  Validation Loss: 1.908
38220
Training Epoch 198 --- Training Accuracy:  96.5%, Validation Accuracy:  51.6%,  Validation Loss: 1.911
38415
Training Epoch 199 --- Training Accuracy:  94.9%, Validation Accuracy:  52.5%,  Validation Loss: 1.903
38610
Training Epoch 200 --- Training Accuracy:  95.7%, Validation Accuracy:  53.1%,  Validation Loss: 1.902
38805
Training Epoch 201 --- Training Accuracy:  95.3%, Validation Accuracy:  51.2%,  Validation Loss: 1.924
39000
Training Epoch 202 --- Training Accuracy:  95.3%, Validation Accuracy:  51.5%,  Validation Loss: 1.911
39195
Training Epoch 203 --- Training Accuracy:  95.7%, Validation Accuracy:  53.1%,  Validation Loss: 1.903
39390
Training Epoch 204 --- Training Accuracy:  94.1%, Validation Accuracy:  51.5%,  Validation Loss: 1.918
39585
Training Epoch 205 --- Training Accuracy:  96.5%, Validation Accuracy:  51.2%,  Validation Loss: 1.908
39780
Training Epoch 206 --- Training Accuracy:  94.9%, Validation Accuracy:  51.6%,  Validation Loss: 1.912
39975
Training Epoch 207 --- Training Accuracy:  96.1%, Validation Accuracy:  51.2%,  Validation Loss: 1.919
40170
Training Epoch 208 --- Training Accuracy:  96.1%, Validation Accuracy:  49.8%,  Validation Loss: 1.924
40365
Training Epoch 209 --- Training Accuracy:  95.7%, Validation Accuracy:  51.6%,  Validation Loss: 1.917
40560
Training Epoch 210 --- Training Accuracy:  96.5%, Validation Accuracy:  51.2%,  Validation Loss: 1.914
40755
Training Epoch 211 --- Training Accuracy:  96.9%, Validation Accuracy:  52.2%,  Validation Loss: 1.904
40950
Training Epoch 212 --- Training Accuracy:  94.1%, Validation Accuracy:  52.1%,  Validation Loss: 1.909
41145
Training Epoch 213 --- Training Accuracy:  94.1%, Validation Accuracy:  52.6%,  Validation Loss: 1.906
41340
Training Epoch 214 --- Training Accuracy:  93.4%, Validation Accuracy:  50.7%,  Validation Loss: 1.911
41535
Training Epoch 215 --- Training Accuracy:  95.3%, Validation Accuracy:  50.1%,  Validation Loss: 1.920
41730
Training Epoch 216 --- Training Accuracy:  96.1%, Validation Accuracy:  50.7%,  Validation Loss: 1.925
41925
Training Epoch 217 --- Training Accuracy:  95.7%, Validation Accuracy:  50.6%,  Validation Loss: 1.918
42120
Training Epoch 218 --- Training Accuracy:  95.7%, Validation Accuracy:  51.7%,  Validation Loss: 1.910
42315
Training Epoch 219 --- Training Accuracy:  94.9%, Validation Accuracy:  52.0%,  Validation Loss: 1.913
42510
Training Epoch 220 --- Training Accuracy:  95.3%, Validation Accuracy:  51.4%,  Validation Loss: 1.917
42705
Training Epoch 221 --- Training Accuracy:  95.7%, Validation Accuracy:  51.1%,  Validation Loss: 1.913
42900
Training Epoch 222 --- Training Accuracy:  95.7%, Validation Accuracy:  51.1%,  Validation Loss: 1.916
43095
Training Epoch 223 --- Training Accuracy:  96.9%, Validation Accuracy:  50.9%,  Validation Loss: 1.918
43290
Training Epoch 224 --- Training Accuracy:  94.5%, Validation Accuracy:  51.0%,  Validation Loss: 1.923
43485
Training Epoch 225 --- Training Accuracy:  95.3%, Validation Accuracy:  51.5%,  Validation Loss: 1.916
43680
Training Epoch 226 --- Training Accuracy:  94.9%, Validation Accuracy:  52.9%,  Validation Loss: 1.902
43875
Training Epoch 227 --- Training Accuracy:  95.7%, Validation Accuracy:  51.5%,  Validation Loss: 1.914
44070
Training Epoch 228 --- Training Accuracy:  96.1%, Validation Accuracy:  50.3%,  Validation Loss: 1.923
44265
Training Epoch 229 --- Training Accuracy:  93.8%, Validation Accuracy:  51.0%,  Validation Loss: 1.927
44460
Training Epoch 230 --- Training Accuracy:  96.1%, Validation Accuracy:  50.2%,  Validation Loss: 1.928
44655
Training Epoch 231 --- Training Accuracy:  96.9%, Validation Accuracy:  51.5%,  Validation Loss: 1.911
44850
Training Epoch 232 --- Training Accuracy:  93.0%, Validation Accuracy:  50.2%,  Validation Loss: 1.929
45045
Training Epoch 233 --- Training Accuracy:  95.3%, Validation Accuracy:  51.3%,  Validation Loss: 1.922
45240
Training Epoch 234 --- Training Accuracy:  96.1%, Validation Accuracy:  51.6%,  Validation Loss: 1.918
45435
Training Epoch 235 --- Training Accuracy:  96.1%, Validation Accuracy:  50.7%,  Validation Loss: 1.916
45630
Training Epoch 236 --- Training Accuracy:  96.1%, Validation Accuracy:  50.8%,  Validation Loss: 1.926
45825
Training Epoch 237 --- Training Accuracy:  95.7%, Validation Accuracy:  51.7%,  Validation Loss: 1.916
46020
Training Epoch 238 --- Training Accuracy:  96.5%, Validation Accuracy:  51.0%,  Validation Loss: 1.926
46215
Training Epoch 239 --- Training Accuracy:  95.3%, Validation Accuracy:  50.4%,  Validation Loss: 1.921
46410
Training Epoch 240 --- Training Accuracy:  94.5%, Validation Accuracy:  52.2%,  Validation Loss: 1.913
46605
Training Epoch 241 --- Training Accuracy:  94.5%, Validation Accuracy:  50.1%,  Validation Loss: 1.924
46800
Training Epoch 242 --- Training Accuracy:  95.7%, Validation Accuracy:  52.4%,  Validation Loss: 1.911
46995
Training Epoch 243 --- Training Accuracy:  96.5%, Validation Accuracy:  51.2%,  Validation Loss: 1.913
47190
Training Epoch 244 --- Training Accuracy:  93.8%, Validation Accuracy:  52.0%,  Validation Loss: 1.912
47385
Training Epoch 245 --- Training Accuracy:  96.1%, Validation Accuracy:  50.7%,  Validation Loss: 1.922
47580
Training Epoch 246 --- Training Accuracy:  94.9%, Validation Accuracy:  51.3%,  Validation Loss: 1.917
47775
Training Epoch 247 --- Training Accuracy:  95.3%, Validation Accuracy:  51.0%,  Validation Loss: 1.927
47970
Training Epoch 248 --- Training Accuracy:  96.1%, Validation Accuracy:  50.9%,  Validation Loss: 1.919
48165
Training Epoch 249 --- Training Accuracy:  94.9%, Validation Accuracy:  50.7%,  Validation Loss: 1.918
48360
Training Epoch 250 --- Training Accuracy:  95.7%, Validation Accuracy:  51.5%,  Validation Loss: 1.918
48555
Training Epoch 251 --- Training Accuracy:  95.7%, Validation Accuracy:  51.3%,  Validation Loss: 1.919
48750
Training Epoch 252 --- Training Accuracy:  96.5%, Validation Accuracy:  51.0%,  Validation Loss: 1.923
48945
Training Epoch 253 --- Training Accuracy:  95.3%, Validation Accuracy:  51.6%,  Validation Loss: 1.913
49140
Training Epoch 254 --- Training Accuracy:  96.1%, Validation Accuracy:  51.6%,  Validation Loss: 1.918
49335
Training Epoch 255 --- Training Accuracy:  93.8%, Validation Accuracy:  50.7%,  Validation Loss: 1.916
49530
Training Epoch 256 --- Training Accuracy:  94.1%, Validation Accuracy:  51.3%,  Validation Loss: 1.911
49725
Training Epoch 257 --- Training Accuracy:  95.3%, Validation Accuracy:  50.3%,  Validation Loss: 1.924
49920
Training Epoch 258 --- Training Accuracy:  96.1%, Validation Accuracy:  49.1%,  Validation Loss: 1.929
50115
Training Epoch 259 --- Training Accuracy:  94.9%, Validation Accuracy:  50.9%,  Validation Loss: 1.922
50310
Training Epoch 260 --- Training Accuracy:  95.3%, Validation Accuracy:  51.6%,  Validation Loss: 1.919
50505
Training Epoch 261 --- Training Accuracy:  95.7%, Validation Accuracy:  50.8%,  Validation Loss: 1.914
50700
Training Epoch 262 --- Training Accuracy:  96.5%, Validation Accuracy:  51.6%,  Validation Loss: 1.907
50895
Training Epoch 263 --- Training Accuracy:  96.5%, Validation Accuracy:  50.7%,  Validation Loss: 1.925
51090
Training Epoch 264 --- Training Accuracy:  95.7%, Validation Accuracy:  51.2%,  Validation Loss: 1.919
51285
Training Epoch 265 --- Training Accuracy:  95.3%, Validation Accuracy:  51.2%,  Validation Loss: 1.920
51480
Training Epoch 266 --- Training Accuracy:  96.1%, Validation Accuracy:  50.1%,  Validation Loss: 1.928
51675
Training Epoch 267 --- Training Accuracy:  96.5%, Validation Accuracy:  50.7%,  Validation Loss: 1.909
51870
Training Epoch 268 --- Training Accuracy:  94.5%, Validation Accuracy:  51.8%,  Validation Loss: 1.914
52065
Training Epoch 269 --- Training Accuracy:  96.9%, Validation Accuracy:  52.0%,  Validation Loss: 1.913
52260
Training Epoch 270 --- Training Accuracy:  95.7%, Validation Accuracy:  51.1%,  Validation Loss: 1.908
52455
Training Epoch 271 --- Training Accuracy:  97.3%, Validation Accuracy:  51.0%,  Validation Loss: 1.919
52650
Training Epoch 272 --- Training Accuracy:  96.1%, Validation Accuracy:  51.5%,  Validation Loss: 1.915
52845
Training Epoch 273 --- Training Accuracy:  95.3%, Validation Accuracy:  51.7%,  Validation Loss: 1.911
53040
Training Epoch 274 --- Training Accuracy:  95.7%, Validation Accuracy:  49.5%,  Validation Loss: 1.924
53235
Training Epoch 275 --- Training Accuracy:  94.9%, Validation Accuracy:  51.9%,  Validation Loss: 1.913
53430
Training Epoch 276 --- Training Accuracy:  95.3%, Validation Accuracy:  51.3%,  Validation Loss: 1.907
53625
Training Epoch 277 --- Training Accuracy:  94.9%, Validation Accuracy:  51.3%,  Validation Loss: 1.920
53820
Training Epoch 278 --- Training Accuracy:  96.1%, Validation Accuracy:  51.1%,  Validation Loss: 1.922
54015
Training Epoch 279 --- Training Accuracy:  96.9%, Validation Accuracy:  50.8%,  Validation Loss: 1.925
54210
Training Epoch 280 --- Training Accuracy:  96.1%, Validation Accuracy:  52.9%,  Validation Loss: 1.905
54405
Training Epoch 281 --- Training Accuracy:  96.5%, Validation Accuracy:  51.0%,  Validation Loss: 1.927
54600
Training Epoch 282 --- Training Accuracy:  97.3%, Validation Accuracy:  51.5%,  Validation Loss: 1.916
54795
Training Epoch 283 --- Training Accuracy:  95.3%, Validation Accuracy:  50.8%,  Validation Loss: 1.913
54990
Training Epoch 284 --- Training Accuracy:  96.5%, Validation Accuracy:  51.5%,  Validation Loss: 1.911
55185
Training Epoch 285 --- Training Accuracy:  95.7%, Validation Accuracy:  52.1%,  Validation Loss: 1.909
55380
Training Epoch 286 --- Training Accuracy:  94.1%, Validation Accuracy:  52.0%,  Validation Loss: 1.904
55575
Training Epoch 287 --- Training Accuracy:  96.5%, Validation Accuracy:  51.8%,  Validation Loss: 1.912
55770
Training Epoch 288 --- Training Accuracy:  95.7%, Validation Accuracy:  51.4%,  Validation Loss: 1.914
55965
Training Epoch 289 --- Training Accuracy:  97.3%, Validation Accuracy:  52.0%,  Validation Loss: 1.912
56160
Training Epoch 290 --- Training Accuracy:  96.9%, Validation Accuracy:  52.0%,  Validation Loss: 1.915
56355
Training Epoch 291 --- Training Accuracy:  96.5%, Validation Accuracy:  50.4%,  Validation Loss: 1.923
56550
Training Epoch 292 --- Training Accuracy:  94.1%, Validation Accuracy:  50.5%,  Validation Loss: 1.922
56745
Training Epoch 293 --- Training Accuracy:  96.9%, Validation Accuracy:  52.0%,  Validation Loss: 1.913
56940
Training Epoch 294 --- Training Accuracy:  95.3%, Validation Accuracy:  52.2%,  Validation Loss: 1.914
57135
Training Epoch 295 --- Training Accuracy:  96.1%, Validation Accuracy:  51.2%,  Validation Loss: 1.920
57330
Training Epoch 296 --- Training Accuracy:  97.3%, Validation Accuracy:  51.8%,  Validation Loss: 1.912
57525
Training Epoch 297 --- Training Accuracy:  96.5%, Validation Accuracy:  50.6%,  Validation Loss: 1.923
57720
Training Epoch 298 --- Training Accuracy:  93.4%, Validation Accuracy:  50.4%,  Validation Loss: 1.925
57915
Training Epoch 299 --- Training Accuracy:  94.9%, Validation Accuracy:  51.5%,  Validation Loss: 1.915
58110
Training Epoch 300 --- Training Accuracy:  96.9%, Validation Accuracy:  52.0%,  Validation Loss: 1.915
58305
Training Epoch 301 --- Training Accuracy:  94.9%, Validation Accuracy:  51.7%,  Validation Loss: 1.912
58500
Training Epoch 302 --- Training Accuracy:  96.1%, Validation Accuracy:  51.2%,  Validation Loss: 1.918
58695
Training Epoch 303 --- Training Accuracy:  93.4%, Validation Accuracy:  51.2%,  Validation Loss: 1.915
58890
Training Epoch 304 --- Training Accuracy:  96.5%, Validation Accuracy:  51.5%,  Validation Loss: 1.916
59085
Training Epoch 305 --- Training Accuracy:  96.9%, Validation Accuracy:  51.0%,  Validation Loss: 1.917
59280
Training Epoch 306 --- Training Accuracy:  96.1%, Validation Accuracy:  51.1%,  Validation Loss: 1.916
59475
Training Epoch 307 --- Training Accuracy:  96.5%, Validation Accuracy:  51.3%,  Validation Loss: 1.918
59670
Training Epoch 308 --- Training Accuracy:  96.5%, Validation Accuracy:  52.1%,  Validation Loss: 1.909
59865
60000
]0;sid@blueberry: ~/rddnn[01;32msid@blueberry[00m:[01;34m~/rddnn[00m$ ls
60k_7layerfc_nodropout.txt  [0m[01;35mgraph.png[0m          [01;34m__pycache__[0m     [01;34mutil[0m
[01;32mcifar_train.py[0m              [01;34mlogs[0m               [01;32mskip_layers.py[0m  [01;34mvalidation_dir[0m
[01;32mdataset.py[0m                  [01;34mmodels[0m             [01;34mtemp[0m
dataset.pyc                 [01;32mno_skip_layers.py[0m  [01;34mtrain_dir[0m
]0;sid@blueberry: ~/rddnn[01;32msid@blueberry[00m:[01;34m~/rddnn[00m$ mv [K[K[Kcd logs
]0;sid@blueberry: ~/rddnn/logs[01;32msid@blueberry[00m:[01;34m~/rddnn/logs[00m$ ls
[0m[01;32m100k_6layerfc.txt[0m  60k_3layerfc.txt             60k_7layerfc.txt  [01;32mplot.py[0m
[01;32m4_layer_fc.txt[0m     60k_7layerfc_0.3dropout.txt  [01;32mgraph.png[0m
]0;sid@blueberry: ~/rddnn/logs[01;32msid@blueberry[00m:[01;34m~/rddnn/logs[00m$ mv [K[K[Ksoure[Kce ../ten[Ks[Kns[K[K[K[K[K[K[K[K[K[K[K[K[K[Kcd [K ..
]0;sid@blueberry: ~/rddnn[01;32msid@blueberry[00m:[01;34m~/rddnn[00m$ source  [K../tensorflow/bin/a
bash: ../tensorflow/bin/a: No such file or directory
]0;sid@blueberry: ~/rddnn[01;32msid@blueberry[00m:[01;34m~/rddnn[00m$ source ../tensorflow/bin/activate
(tensorflow) ]0;sid@blueberry: ~/rddnn[01;32msid@blueberry[00m:[01;34m~/rddnn[00m$ source ../tensorflow/bin/activate[Kpythonp[K plot.p[K[K[K[K[K[K[K[K[K[K[K[K[Kpython /logs[K[K[K[K[Klogs/plot.py 
['100k_6layerfc.txt', '60k_3layerfc.txt', '60k_7layerfc.txt', '4_layer_fc.txt', '60k_7layerfc_0.3dropout.txt']
(tensorflow) ]0;sid@blueberry: ~/rddnn[01;32msid@blueberry[00m:[01;34m~/rddnn[00m$ gr[K[Ksource ~.[K/.bashrc
]0;sid@blueberry: ~/rddnn[01;32msid@blueberry[00m:[01;34m~/rddnn[00m$ graph_data
https://transfer.sh/jHZig/graph.png]0;sid@blueberry: ~/rddnn[01;32msid@blueberry[00m:[01;34m~/rddnn[00m$ graph_datasource ~/.bashrcpython logs/plot.py [C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[Kcd logs/
]0;sid@blueberry: ~/rddnn/logs[01;32msid@blueberry[00m:[01;34m~/rddnn/logs[00m$ python plot.py 
['100k_6layerfc.txt', '60k_3layerfc.txt', '60k_7layerfc.txt', '4_layer_fc.txt', '60k_7layerfc_0.3dropout.txt']
]0;sid@blueberry: ~/rddnn/logs[01;32msid@blueberry[00m:[01;34m~/rddnn/logs[00m$ source ~/.bashrc
]0;sid@blueberry: ~/rddnn/logs[01;32msid@blueberry[00m:[01;34m~/rddnn/logs[00m$ graph_data
https://transfer.sh/tVFlR/graph.png]0;sid@blueberry: ~/rddnn/logs[01;32msid@blueberry[00m:[01;34m~/rddnn/logs[00m$ graph_data[Ksudo vim cifar[K[K[K[K[K[K[K[K[K[K[K[K[K[Kcd ..
]0;sid@blueberry: ~/rddnn[01;32msid@blueberry[00m:[01;34m~/rddnn[00m$ source ../python3_tf/bin/activate
(python3_tf) ]0;sid@blueberry: ~/rddnn[01;32msid@blueberry[00m:[01;34m~/rddnn[00m$ v[Ksudo vim cifar_train.py 
[sudo] password for sid: 
[?1049h[?1h=[2;1H▽[6n[2;1H  [1;1H]11;?[1;41r[?12;25h[?12l[?25h[27m[23m[m[H[2J[?25l[41;1H"cifar_train.py" 250L, 8282C[>c[1;1H[35mimport[m dataset
[35mimport[m tensorflow [38;5;130mas[m tf
[35mimport[m time
[35mfrom[m datetime [35mimport[m timedelta
[35mimport[m math
[35mimport[m random
[35mimport[m numpy [38;5;130mas[m np
[35mimport[m sys

[34m#Adding Seed so that random initialization is consistent[m
[35mfrom[m numpy.random [35mimport[m seed
seed([31m1[m)
[35mfrom[m tensorflow [35mimport[m set_random_seed
set_random_seed([31m2[m)

batch_size = [31m256[m
val_batch_size = [31m2000[m

[34m#Prepare input data[m
classes = [[31m'airplane'[m, [31m'automobile'[m,[31m'bird'[m,[31m'cat'[m,[31m'deer'[m,[31m'dog'[m,[31m'frog'[m,[31m'horse'[m,[31m'ship'[m,,[21;1H[31m'truck'[m]
num_classes = [36mlen[m(classes)

img_size = [31m32[m
num_channels = [31m3[m
train_path=[31m"train_dir"[m
val_path = [31m"validation_dir"[m

[34m# We shall load all the training and validation images and labels into memory using  [30;1HopenCV and use that during training[m
data = dataset.read_train_sets(train_path, val_path, img_size, classes)


[36mprint[m([31m"Complete reading input data. Will Now print a snippet of it"[m)
[36mprint[m([31m"Number of files in Training-set:[m[35m\t\t[m[31m{}"[m.format([36mlen[m(data.train.labels)))
[36mprint[m([31m"Number of files in Validation-set:[m[35m\t[m[31m{}"[m.format([36mlen[m(data.valid.labels)))

session = tf.Session()
x = tf.placeholder(tf.float32, shape=[[36mNone[m, img_size,img_size,num_channels], name=[31m'xx[40;1H'[m)[41;67H1,1[11CTop[1;1H[?12l[?25h[?25l[41;67H2[2;1H[?12l[?25h[?25l[41;67H3[3;1H[?12l[?25h[?25l[41;67H4[4;1H[?12l[?25h[?25l[41;67H5[5;1H[?12l[?25h[?25l[41;67H6[6;1H[?12l[?25h[?25l[41;67H7[7;1H[?12l[?25h[?25l[41;67H8[8;1H[?12l[?25h[?25l[41;67H9,0-1[9;1H[?12l[?25h[?25l[41;67H10,1 [10;1H[?12l[?25h[?25l[41;68H1[11;1H[?12l[?25h[?25l[41;68H2[12;1H[?12l[?25h[?25l[41;68H3[13;1H[?12l[?25h[?25l[41;68H4[14;1H[?12l[?25h[?25l[41;68H5,0-1[15;1H[?12l[?25h[?25l[41;68H6,1  [16;1H[?12l[?25h[?25l[41;68H7[17;1H[?12l[?25h[?25l[41;68H8,0-1[18;1H[?12l[?25h[?25l[41;68H9,1  [19;1H[?12l[?25h[?25l[41;67H20[20;1H[?12l[?25h[?25l[41;68H1[22;1H[?12l[?25h[?25l[41;68H2,0-1[23;1H[?12l[?25h[?25l[41;68H3,1  [24;1H[?12l[?25h[?25l[41;68H4[25;1H[?12l[?25h[?25l[41;68H5[26;1H[?12l[?25h[?25l[41;68H6[27;1H[?12l[?25h[?25l[41;68H7,0-1[28;1H[?12l[?25h[?25l[41;68H8,1  [29;1H[?12l[?25h[?25l[41;68H9[31;1H[?12l[?25h[?25l[41;67H30,0-1[32;1H[?12l[?25h[?25l[41;68H1[33;1H[?12l[?25h[?25l[41;68H2,1  [34;1H[?12l[?25h[?25l[41;68H3[35;1H[?12l[?25h[?25l[41;68H4[36;1H[?12l[?25h[?25l[41;68H5,0-1[37;1H[?12l[?25h[?25l[41;68H6,1  [38;1H[?12l[?25h[?25l[41;68H7[39;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[41;1H[K[41;67H38,0-1[9C0%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1H[34m## labels[m[41;67H[K[41;67H39,1[11C0%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1Hy_true = tf.placeholder(tf.float32, shape=[[36mNone[m, num_classes], name=[31m'y_true'[m)[41;67H[K[41;67H40,1[11C1%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1Hy_true_cls = tf.argmax(y_true, dimension=[31m1[m)[41;67H[K[41;67H41,1[11C1%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[41;67H[K[41;67H42,0-1[9C2%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1H[34m##Network graph params[m[41;67H[K[41;67H43,1[11C2%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1Hfc1_layer_size = [31m512[m[41;67H[K[41;67H44,1[11C3%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1Hfc2_layer_size = [31m512[m[41;67H[K[41;67H45,1[11C3%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1Hfc3_layer_size = [31m512[m[41;67H[K[41;67H46,1[11C4%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1Hfc4_layer_size = [31m512[m[41;67H[K[41;67H47,1[11C4%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1Hfc5_layer_size = [31m512[m[41;67H[K[41;67H48,1[11C5%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1Hfc6_layer_size = [31m512[m[41;67H[K[41;67H49,1[11C5%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1Hfc7_layer_size = [31m512[m[41;67H[K[41;67H50,1[11C6%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1Hfc8_layer_size = [31m512[m[41;67H[K[41;67H51,1[11C6%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1H[31m'''[m[41;67H[K[41;67H52,1[11C7%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1H[31mfc9_layer_size = 512[m[41;67H[K[41;67H53,1[11C7%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1H[31mfc10_layer_size = 512[m[41;67H[K[41;67H54,1[11C7%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1H[31mfc11_layer_size = 1024[m[41;67H[K[41;67H55,1[11C8%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1H[31mfc12_layer_size = 1024[m[41;67H[K[41;67H56,1[11C8%[40;1H[?12l[?25h[?25l[1;40r[1;1H[2M[1;41r[39;1H[31m'''[m[41;67H[K[41;67H57,1[11C9%[39;1H[?12l[?25h[?25l[41;68H8,0-1[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1H[38;5;130mdef[m [36mcreate_weights[m(shape, name):[41;67H[K[41;67H59,1[11C9%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;5H[38;5;130mreturn[m tf.Variable(tf.truncated_normal(shape, stddev=[31m0.05[m), name=name)[41;67H[K[41;67H60,1[10C10%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[41;67H[K[41;67H61,0-1[8C10%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1H[38;5;130mdef[m [36mcreate_biases[m(size, name):[41;67H[K[41;67H62,1[10C11%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;5H[38;5;130mreturn[m tf.Variable(tf.constant([31m0.05[m, shape=[size]), name=name)[41;67H[K[41;67H63,1[10C11%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[41;67H[K[41;67H64,0-1[8C12%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1H[34m# First layer must be a flatten layer[m[41;67H[K[41;67H65,1[10C12%[40;1H[?12l[?25h[?25l[1;40r[1;1H[2M[1;41r[39;1H[38;5;130mdef[m [36mcreate_flatten_layer[m([36minput[m, batch_size, img_size, num_channels):
    [34m#We know that the shape of the layer will be [batch_size img_size img_size num_c[m[40;1H[94m@                                                                                   [m[41;67H[K[41;67H66,1[10C13%[39;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[39;1H    [34m#We know that the shape of the layer will be [batch_size img_size img_size num_cc[40;1Hhannels] [m[41;67H[K[41;67H67,1[10C13%[39;1H[?12l[?25h[?25l[41;68H6[38;1H[?12l[?25h[?25l[41;68H5[37;1H[?12l[?25h[?25l[41;68H4,0-1[36;1H[?12l[?25h[?25l[41;68H3,1  [35;1H[?12l[?25h[?25l[41;68H2[34;1H[?12l[?25h[?25l[41;68H1,0-1[33;1H[?12l[?25h[?25l[41;68H0,1  [32;1H[?12l[?25h[?25l[41;67H59[31;1H[?12l[?25h[?25l[41;68H8,0-1[30;1H[?12l[?25h[?25l[41;68H7,1  [29;1H[?12l[?25h[?25l[41;68H6[28;1H[?12l[?25h[?25l[41;68H5[27;1H[?12l[?25h[?25l[41;68H4[26;1H[?12l[?25h[?25l[41;68H3[25;1H[?12l[?25h[?25l[41;68H2[24;1H[?12l[?25h[?25l[41;70H2[24;2H[?12l[?25h[?25l[41;70H3[24;3H[?12l[?25h[?25l[41;68H1[23;3H[?12l[?25h[?25l[41;70H20[23;20H[?12l[?25h[?25l[41;1H[1m-- INSERT --[m[41;67H[K[41;67H51,20[9C13%[23;20H[?12l[?25h[?25l[41;71H1[23;21H[?12l[?25h[?25l[23;20H[K[41;71H0[23;20H[?12l[?25h[?25l[23;19H[K[41;70H19[23;19H[?12l[?25h[?25l[23;18H[K[41;71H8[23;18H[?12l[?25h[?25l[31m1[m[41;71H9[23;19H[?12l[?25h[?25l[31m0[m[41;70H20[23;20H[?12l[?25h[?25l[31m2[m[41;71H1[23;21H[?12l[?25h[?25l[31m4[m[41;71H2[23;22H[?12l[?25h[?25l[41;68H0,21[22;21H[?12l[?25h[?25l[22;20H[K[41;71H0[22;20H[?12l[?25h[?25l[22;19H[K[41;70H19[22;19H[?12l[?25h[?25l[22;18H[K[41;71H8[22;18H[?12l[?25h[?25l[31m2[m[41;71H9[22;19H[?12l[?25h[?25l[31m0[m[41;70H20[22;20H[?12l[?25h[?25l[22;19H[K[41;70H19[22;19H[?12l[?25h[?25l[22;18H[K[41;71H8[22;18H[?12l[?25h[?25l[31m1[m[41;71H9[22;19H[?12l[?25h[?25l[31m0[m[41;70H20[22;20H[?12l[?25h[?25l[31m2[m[41;71H1[22;21H[?12l[?25h[?25l[31m4[m[41;71H2[22;22H[?12l[?25h[?25l[41;67H49,21[21;21H[?12l[?25h[?25l[21;20H[K[41;71H0[21;20H[?12l[?25h[?25l[21;19H[K[41;70H19[21;19H[?12l[?25h[?25l[21;18H[K[41;71H8[21;18H[?12l[?25h[?25l[31m1[m[41;71H9[21;19H[?12l[?25h[?25l[31m0[m[41;70H20[21;20H[?12l[?25h[?25l[31m2[m[41;71H1[21;21H[?12l[?25h[?25l[31m4[m[41;71H2[21;22H[?12l[?25h[?25l[41;68H8[20;22H[?12l[?25h[?25l[41;71H1[20;21H[?12l[?25h[?25l[20;20H[K[41;71H0[20;20H[?12l[?25h[?25l[20;19H[K[41;70H19[20;19H[?12l[?25h[?25l[20;18H[K[41;71H8[20;18H[?12l[?25h[?25l[31m1[m[41;71H9[20;19H[?12l[?25h[?25l[31m0[m[41;70H20[20;20H[?12l[?25h[?25l[31m2[m[41;71H1[20;21H[?12l[?25h[?25l[31m4[m[41;71H2[20;22H[?12l[?25h[?25l[41;68H7[19;22H[?12l[?25h[?25l[41;71H1[19;21H[?12l[?25h[?25l[19;20H[K[41;71H0[19;20H[?12l[?25h[?25l[19;19H[K[41;70H19[19;19H[?12l[?25h[?25l[19;18H[K[41;71H8[19;18H[?12l[?25h[?25l[31m1[m[41;71H9[19;19H[?12l[?25h[?25l[31m0[m[41;70H20[19;20H[?12l[?25h[?25l[31m2[m[41;71H1[19;21H[?12l[?25h[?25l[31m4[m[41;71H2[19;22H[?12l[?25h[?25l[41;68H6,21[18;21H[?12l[?25h[?25l[18;20H[K[41;71H0[18;20H[?12l[?25h[?25l[18;19H[K[41;70H19[18;19H[?12l[?25h[?25l[18;18H[K[41;71H8[18;18H[?12l[?25h[?25l[31m1[m[41;71H9[18;19H[?12l[?25h[?25l[31m0[m[41;70H20[18;20H[?12l[?25h[?25l[31m2[m[41;71H1[18;21H[?12l[?25h[?25l[31m4[m[41;71H2[18;22H[?12l[?25h[?25l[41;68H5,21[17;21H[?12l[?25h[?25l[17;20H[K[41;71H0[17;20H[?12l[?25h[?25l[17;19H[K[41;70H19[17;19H[?12l[?25h[?25l[17;18H[K[41;71H8[17;18H[?12l[?25h[?25l[31m1[m[41;71H9[17;19H[?12l[?25h[?25l[31m0[m[41;70H20[17;20H[?12l[?25h[?25l[31m2[m[41;71H1[17;21H[?12l[?25h[?25l[31m4[m[41;71H2[17;22H[?12l[?25h[?25l[41;68H4,21[16;21H[?12l[?25h[?25l[16;20H[K[41;71H0[16;20H[?12l[?25h[?25l[16;19H[K[41;70H19[16;19H[?12l[?25h[?25l[16;18H[K[41;71H8[16;18H[?12l[?25h[?25l[31m1[m[41;71H9[16;19H[?12l[?25h[?25l[31m0[m[41;70H20[16;20H[?12l[?25h[?25l[31m2[m[41;71H1[16;21H[?12l[?25h[?25l[31m4[m[41;71H2[16;22H[?12l[?25h[?25l[17;40r[17;1H[L[1;41r[40;1H[94m@                                                                                   [m[41;67H[K[41;67H45,1[10C13%[17;1H[?12l[?25h[?25l[16;40r[40;1H
[1;41r[16;1Hfc1_layer_size = [31m1024[m[39;1H    [34m#We know that the shape of the layer will be [batch_size img_size img_size num_cc[40;1Hhannels] [m[41;67H[K[41;67H44,22[9C13%[16;22H[?12l[?25h[41;1H[K[16;21H[?25l[41;67H44,21[9C13%[16;21H[?12l[?25h[?25l[41;67H[K[41;1H:[?12l[?25hw[?25l[?12l[?25hq[?25l[?12l[?25h[?25l"cifar_train.py" 250L, 8288C written
[?1l>[?12l[?25h[?1049l(python3_tf) ]0;sid@blueberry: ~/rddnn[01;32msid@blueberry[00m:[01;34m~/rddnn[00m$ sudo vim cifar_train.py ource ../python3_tf/bin/activatecd ..[Kgraph_datasource ~/.bashrc[1Ppython plot.py [K[K[K[K[K[K[K[K[K[K[K[K[K[K[Kpython cifar_train.py 
/home/sid/python3_tf/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Going to read training images
Now going to read airplane files (Index: 0)
Now going to read automobile files (Index: 1)
Now going to read bird files (Index: 2)
Now going to read cat files (Index: 3)
Now going to read deer files (Index: 4)
Now going to read dog files (Index: 5)
Now going to read frog files (Index: 6)
Now going to read horse files (Index: 7)
Now going to read ship files (Index: 8)
Now going to read truck files (Index: 9)
Going to read training images
Now going to read airplane files (Index: 0)
Now going to read automobile files (Index: 1)
Now going to read bird files (Index: 2)
Now going to read cat files (Index: 3)
Now going to read deer files (Index: 4)
Now going to read dog files (Index: 5)
Now going to read frog files (Index: 6)
Now going to read horse files (Index: 7)
Now going to read ship files (Index: 8)
Now going to read truck files (Index: 9)
Complete reading input data. Will Now print a snippet of it
Number of files in Training-set:		50000
Number of files in Validation-set:	10000
2018-06-01 16:12:53.770558: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-06-01 16:12:53.843507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-06-01 16:12:53.843717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: GeForce GTX 1060 6GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:01:00.0
totalMemory: 5.93GiB freeMemory: 5.65GiB
2018-06-01 16:12:53.843729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1)
WARNING:tensorflow:From cifar_train.py:41: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.
Instructions for updating:
Use the `axis` argument instead
WARNING:tensorflow:From cifar_train.py:198: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See tf.nn.softmax_cross_entropy_with_logits_v2.

Training Epoch 1 --- Training Accuracy:  19.9%, Validation Accuracy:  14.7%,  Validation Loss: 2.274
0
Training Epoch 2 --- Training Accuracy:  37.9%, Validation Accuracy:  36.1%,  Validation Loss: 1.973
195
Training Epoch 3 --- Training Accuracy:  40.2%, Validation Accuracy:  40.7%,  Validation Loss: 1.944
390
Training Epoch 4 --- Training Accuracy:  42.2%, Validation Accuracy:  41.2%,  Validation Loss: 1.922
585
Training Epoch 5 --- Training Accuracy:  47.7%, Validation Accuracy:  43.9%,  Validation Loss: 1.896
780
Training Epoch 6 --- Training Accuracy:  46.5%, Validation Accuracy:  45.3%,  Validation Loss: 1.884
975
Training Epoch 7 --- Training Accuracy:  50.8%, Validation Accuracy:  45.8%,  Validation Loss: 1.882
1170
Training Epoch 8 --- Training Accuracy:  53.1%, Validation Accuracy:  46.2%,  Validation Loss: 1.878
1365
Training Epoch 9 --- Training Accuracy:  54.7%, Validation Accuracy:  46.5%,  Validation Loss: 1.878
1560
Training Epoch 10 --- Training Accuracy:  52.3%, Validation Accuracy:  47.4%,  Validation Loss: 1.870
1755
Training Epoch 11 --- Training Accuracy:  53.1%, Validation Accuracy:  47.6%,  Validation Loss: 1.878
1950
Training Epoch 12 --- Training Accuracy:  60.9%, Validation Accuracy:  48.6%,  Validation Loss: 1.864
2145
Training Epoch 13 --- Training Accuracy:  59.8%, Validation Accuracy:  48.1%,  Validation Loss: 1.860
2340
Training Epoch 14 --- Training Accuracy:  62.1%, Validation Accuracy:  49.1%,  Validation Loss: 1.854
2535
Training Epoch 15 --- Training Accuracy:  61.7%, Validation Accuracy:  48.2%,  Validation Loss: 1.873
2730
Training Epoch 16 --- Training Accuracy:  58.2%, Validation Accuracy:  47.5%,  Validation Loss: 1.884
2925
Training Epoch 17 --- Training Accuracy:  60.5%, Validation Accuracy:  47.5%,  Validation Loss: 1.881
3120
Training Epoch 18 --- Training Accuracy:  64.8%, Validation Accuracy:  47.0%,  Validation Loss: 1.878
3315
Training Epoch 19 --- Training Accuracy:  58.2%, Validation Accuracy:  46.7%,  Validation Loss: 1.890
3510
Training Epoch 20 --- Training Accuracy:  62.5%, Validation Accuracy:  47.7%,  Validation Loss: 1.876
3705
Training Epoch 21 --- Training Accuracy:  66.4%, Validation Accuracy:  50.4%,  Validation Loss: 1.861
3900
Training Epoch 22 --- Training Accuracy:  60.9%, Validation Accuracy:  49.1%,  Validation Loss: 1.880
4095
Training Epoch 23 --- Training Accuracy:  66.8%, Validation Accuracy:  48.4%,  Validation Loss: 1.870
4290
Training Epoch 24 --- Training Accuracy:  64.8%, Validation Accuracy:  49.3%,  Validation Loss: 1.876
4485
Training Epoch 25 --- Training Accuracy:  67.6%, Validation Accuracy:  48.4%,  Validation Loss: 1.872
4680
Training Epoch 26 --- Training Accuracy:  69.1%, Validation Accuracy:  51.2%,  Validation Loss: 1.862
4875
Training Epoch 27 --- Training Accuracy:  71.5%, Validation Accuracy:  51.0%,  Validation Loss: 1.849
5070
Training Epoch 28 --- Training Accuracy:  69.9%, Validation Accuracy:  50.5%,  Validation Loss: 1.850
5265
Training Epoch 29 --- Training Accuracy:  69.1%, Validation Accuracy:  49.8%,  Validation Loss: 1.870
5460
Training Epoch 30 --- Training Accuracy:  72.7%, Validation Accuracy:  51.0%,  Validation Loss: 1.866
5655
Training Epoch 31 --- Training Accuracy:  74.2%, Validation Accuracy:  51.7%,  Validation Loss: 1.859
5850
Training Epoch 32 --- Training Accuracy:  78.9%, Validation Accuracy:  52.1%,  Validation Loss: 1.849
6045
Training Epoch 33 --- Training Accuracy:  77.0%, Validation Accuracy:  52.4%,  Validation Loss: 1.859
6240
Training Epoch 34 --- Training Accuracy:  74.6%, Validation Accuracy:  51.5%,  Validation Loss: 1.855
6435
Training Epoch 35 --- Training Accuracy:  75.0%, Validation Accuracy:  52.4%,  Validation Loss: 1.856
6630
Training Epoch 36 --- Training Accuracy:  77.3%, Validation Accuracy:  52.2%,  Validation Loss: 1.856
6825
Training Epoch 37 --- Training Accuracy:  77.3%, Validation Accuracy:  50.1%,  Validation Loss: 1.875
7020
Training Epoch 38 --- Training Accuracy:  77.3%, Validation Accuracy:  52.5%,  Validation Loss: 1.858
7215
Training Epoch 39 --- Training Accuracy:  77.0%, Validation Accuracy:  52.1%,  Validation Loss: 1.862
7410
Training Epoch 40 --- Training Accuracy:  78.9%, Validation Accuracy:  51.8%,  Validation Loss: 1.866
7605
Training Epoch 41 --- Training Accuracy:  78.5%, Validation Accuracy:  51.7%,  Validation Loss: 1.869
7800
Training Epoch 42 --- Training Accuracy:  77.0%, Validation Accuracy:  51.5%,  Validation Loss: 1.862
7995
Training Epoch 43 --- Training Accuracy:  82.0%, Validation Accuracy:  51.8%,  Validation Loss: 1.870
8190
Training Epoch 44 --- Training Accuracy:  82.0%, Validation Accuracy:  51.4%,  Validation Loss: 1.870
8385
Training Epoch 45 --- Training Accuracy:  80.1%, Validation Accuracy:  50.8%,  Validation Loss: 1.871
8580
Training Epoch 46 --- Training Accuracy:  84.0%, Validation Accuracy:  51.8%,  Validation Loss: 1.869
8775
Training Epoch 47 --- Training Accuracy:  80.9%, Validation Accuracy:  49.8%,  Validation Loss: 1.889
8970
Training Epoch 48 --- Training Accuracy:  83.6%, Validation Accuracy:  51.5%,  Validation Loss: 1.883
9165
Training Epoch 49 --- Training Accuracy:  84.4%, Validation Accuracy:  51.2%,  Validation Loss: 1.878
9360
Training Epoch 50 --- Training Accuracy:  84.0%, Validation Accuracy:  51.4%,  Validation Loss: 1.893
9555
Training Epoch 51 --- Training Accuracy:  84.0%, Validation Accuracy:  50.2%,  Validation Loss: 1.899
9750
Training Epoch 52 --- Training Accuracy:  84.0%, Validation Accuracy:  50.2%,  Validation Loss: 1.887
9945
Training Epoch 53 --- Training Accuracy:  84.4%, Validation Accuracy:  51.8%,  Validation Loss: 1.886
10140
Training Epoch 54 --- Training Accuracy:  85.2%, Validation Accuracy:  51.5%,  Validation Loss: 1.887
10335
Training Epoch 55 --- Training Accuracy:  87.5%, Validation Accuracy:  51.8%,  Validation Loss: 1.876
10530
Training Epoch 56 --- Training Accuracy:  86.7%, Validation Accuracy:  51.2%,  Validation Loss: 1.886
10725
Training Epoch 57 --- Training Accuracy:  85.5%, Validation Accuracy:  51.3%,  Validation Loss: 1.898
10920
Training Epoch 58 --- Training Accuracy:  87.9%, Validation Accuracy:  51.2%,  Validation Loss: 1.899
11115
Training Epoch 59 --- Training Accuracy:  87.5%, Validation Accuracy:  51.6%,  Validation Loss: 1.895
11310
Training Epoch 60 --- Training Accuracy:  88.7%, Validation Accuracy:  51.6%,  Validation Loss: 1.894
11505
Training Epoch 61 --- Training Accuracy:  89.8%, Validation Accuracy:  51.7%,  Validation Loss: 1.892
11700
Training Epoch 62 --- Training Accuracy:  88.3%, Validation Accuracy:  52.0%,  Validation Loss: 1.889
11895
Training Epoch 63 --- Training Accuracy:  90.2%, Validation Accuracy:  51.0%,  Validation Loss: 1.899
12090
Training Epoch 64 --- Training Accuracy:  87.5%, Validation Accuracy:  51.2%,  Validation Loss: 1.906
12285
Training Epoch 65 --- Training Accuracy:  91.8%, Validation Accuracy:  50.7%,  Validation Loss: 1.901
12480
Training Epoch 66 --- Training Accuracy:  93.4%, Validation Accuracy:  52.2%,  Validation Loss: 1.895
12675
Training Epoch 67 --- Training Accuracy:  91.4%, Validation Accuracy:  52.4%,  Validation Loss: 1.887
12870
Training Epoch 68 --- Training Accuracy:  90.6%, Validation Accuracy:  53.0%,  Validation Loss: 1.893
13065
Training Epoch 69 --- Training Accuracy:  92.2%, Validation Accuracy:  51.9%,  Validation Loss: 1.904
13260
Training Epoch 70 --- Training Accuracy:  92.2%, Validation Accuracy:  51.8%,  Validation Loss: 1.903
13455
Training Epoch 71 --- Training Accuracy:  93.4%, Validation Accuracy:  51.4%,  Validation Loss: 1.902
13650
Training Epoch 72 --- Training Accuracy:  93.0%, Validation Accuracy:  50.8%,  Validation Loss: 1.902
13845
Training Epoch 73 --- Training Accuracy:  93.4%, Validation Accuracy:  51.1%,  Validation Loss: 1.912
14040
Training Epoch 74 --- Training Accuracy:  91.8%, Validation Accuracy:  52.0%,  Validation Loss: 1.891
14235
Training Epoch 75 --- Training Accuracy:  93.8%, Validation Accuracy:  51.5%,  Validation Loss: 1.905
14430
Training Epoch 76 --- Training Accuracy:  95.3%, Validation Accuracy:  51.8%,  Validation Loss: 1.904
14625
Training Epoch 77 --- Training Accuracy:  94.1%, Validation Accuracy:  50.9%,  Validation Loss: 1.913
14820
Training Epoch 78 --- Training Accuracy:  93.8%, Validation Accuracy:  52.2%,  Validation Loss: 1.900
15015
Training Epoch 79 --- Training Accuracy:  93.8%, Validation Accuracy:  50.1%,  Validation Loss: 1.912
15210
Training Epoch 80 --- Training Accuracy:  93.0%, Validation Accuracy:  51.7%,  Validation Loss: 1.911
15405
Training Epoch 81 --- Training Accuracy:  94.1%, Validation Accuracy:  51.6%,  Validation Loss: 1.896
15600
Training Epoch 82 --- Training Accuracy:  94.5%, Validation Accuracy:  51.3%,  Validation Loss: 1.910
15795
Training Epoch 83 --- Training Accuracy:  94.5%, Validation Accuracy:  52.4%,  Validation Loss: 1.899
15990
Training Epoch 84 --- Training Accuracy:  94.5%, Validation Accuracy:  51.5%,  Validation Loss: 1.906
16185
Training Epoch 85 --- Training Accuracy:  93.8%, Validation Accuracy:  51.2%,  Validation Loss: 1.904
16380
Training Epoch 86 --- Training Accuracy:  93.8%, Validation Accuracy:  50.7%,  Validation Loss: 1.916
16575
Training Epoch 87 --- Training Accuracy:  94.5%, Validation Accuracy:  51.2%,  Validation Loss: 1.905
16770
Training Epoch 88 --- Training Accuracy:  95.3%, Validation Accuracy:  51.4%,  Validation Loss: 1.908
16965
Training Epoch 89 --- Training Accuracy:  95.7%, Validation Accuracy:  51.6%,  Validation Loss: 1.906
17160
Training Epoch 90 --- Training Accuracy:  94.1%, Validation Accuracy:  50.0%,  Validation Loss: 1.920
17355
Training Epoch 91 --- Training Accuracy:  95.3%, Validation Accuracy:  51.5%,  Validation Loss: 1.908
17550
Training Epoch 92 --- Training Accuracy:  94.5%, Validation Accuracy:  51.7%,  Validation Loss: 1.907
17745
Training Epoch 93 --- Training Accuracy:  95.3%, Validation Accuracy:  51.7%,  Validation Loss: 1.912
17940
Training Epoch 94 --- Training Accuracy:  96.1%, Validation Accuracy:  51.6%,  Validation Loss: 1.912
18135
Training Epoch 95 --- Training Accuracy:  95.7%, Validation Accuracy:  50.6%,  Validation Loss: 1.912
18330
Training Epoch 96 --- Training Accuracy:  95.7%, Validation Accuracy:  52.0%,  Validation Loss: 1.909
18525
Training Epoch 97 --- Training Accuracy:  95.3%, Validation Accuracy:  50.5%,  Validation Loss: 1.914
18720
Training Epoch 98 --- Training Accuracy:  96.1%, Validation Accuracy:  52.8%,  Validation Loss: 1.908
18915
Training Epoch 99 --- Training Accuracy:  94.5%, Validation Accuracy:  51.2%,  Validation Loss: 1.913
19110
Training Epoch 100 --- Training Accuracy:  96.5%, Validation Accuracy:  52.4%,  Validation Loss: 1.912
19305
Training Epoch 101 --- Training Accuracy:  95.7%, Validation Accuracy:  51.1%,  Validation Loss: 1.916
19500
Training Epoch 102 --- Training Accuracy:  95.7%, Validation Accuracy:  51.3%,  Validation Loss: 1.912
19695
Training Epoch 103 --- Training Accuracy:  96.1%, Validation Accuracy:  50.6%,  Validation Loss: 1.915
19890
Training Epoch 104 --- Training Accuracy:  94.9%, Validation Accuracy:  51.4%,  Validation Loss: 1.912
20085
Training Epoch 105 --- Training Accuracy:  95.7%, Validation Accuracy:  51.1%,  Validation Loss: 1.914
20280
Training Epoch 106 --- Training Accuracy:  94.1%, Validation Accuracy:  51.7%,  Validation Loss: 1.904
20475
Training Epoch 107 --- Training Accuracy:  94.1%, Validation Accuracy:  51.9%,  Validation Loss: 1.911
20670
Training Epoch 108 --- Training Accuracy:  96.1%, Validation Accuracy:  51.1%,  Validation Loss: 1.912
20865
Training Epoch 109 --- Training Accuracy:  94.9%, Validation Accuracy:  51.1%,  Validation Loss: 1.906
21060
Training Epoch 110 --- Training Accuracy:  95.7%, Validation Accuracy:  51.2%,  Validation Loss: 1.914
21255
Training Epoch 111 --- Training Accuracy:  94.5%, Validation Accuracy:  50.6%,  Validation Loss: 1.925
21450
Training Epoch 112 --- Training Accuracy:  96.1%, Validation Accuracy:  52.9%,  Validation Loss: 1.900
21645
Training Epoch 113 --- Training Accuracy:  94.1%, Validation Accuracy:  50.2%,  Validation Loss: 1.921
21840
Training Epoch 114 --- Training Accuracy:  94.9%, Validation Accuracy:  51.2%,  Validation Loss: 1.921
22035
Training Epoch 115 --- Training Accuracy:  96.9%, Validation Accuracy:  51.3%,  Validation Loss: 1.924
22230
Training Epoch 116 --- Training Accuracy:  95.3%, Validation Accuracy:  51.2%,  Validation Loss: 1.921
22425
Training Epoch 117 --- Training Accuracy:  96.5%, Validation Accuracy:  49.9%,  Validation Loss: 1.930
22620
Training Epoch 118 --- Training Accuracy:  95.7%, Validation Accuracy:  51.0%,  Validation Loss: 1.921
22815
Training Epoch 119 --- Training Accuracy:  95.3%, Validation Accuracy:  50.9%,  Validation Loss: 1.911
23010
Training Epoch 120 --- Training Accuracy:  96.9%, Validation Accuracy:  51.0%,  Validation Loss: 1.914
23205
Training Epoch 121 --- Training Accuracy:  96.1%, Validation Accuracy:  51.0%,  Validation Loss: 1.921
23400
Training Epoch 122 --- Training Accuracy:  96.5%, Validation Accuracy:  52.0%,  Validation Loss: 1.916
23595
Training Epoch 123 --- Training Accuracy:  96.9%, Validation Accuracy:  50.2%,  Validation Loss: 1.919
23790
Training Epoch 124 --- Training Accuracy:  96.1%, Validation Accuracy:  51.2%,  Validation Loss: 1.919
23985
Training Epoch 125 --- Training Accuracy:  96.5%, Validation Accuracy:  51.6%,  Validation Loss: 1.904
24180
Training Epoch 126 --- Training Accuracy:  95.7%, Validation Accuracy:  51.6%,  Validation Loss: 1.907
24375
Training Epoch 127 --- Training Accuracy:  96.9%, Validation Accuracy:  51.2%,  Validation Loss: 1.915
24570
Training Epoch 128 --- Training Accuracy:  95.3%, Validation Accuracy:  49.6%,  Validation Loss: 1.932
24765
Training Epoch 129 --- Training Accuracy:  95.3%, Validation Accuracy:  51.3%,  Validation Loss: 1.912
24960
Training Epoch 130 --- Training Accuracy:  96.1%, Validation Accuracy:  52.0%,  Validation Loss: 1.911
25155
Training Epoch 131 --- Training Accuracy:  95.3%, Validation Accuracy:  51.0%,  Validation Loss: 1.924
25350
Training Epoch 132 --- Training Accuracy:  96.5%, Validation Accuracy:  51.3%,  Validation Loss: 1.917
25545
Training Epoch 133 --- Training Accuracy:  96.9%, Validation Accuracy:  50.7%,  Validation Loss: 1.915
25740
Training Epoch 134 --- Training Accuracy:  95.3%, Validation Accuracy:  50.7%,  Validation Loss: 1.918
25935
Training Epoch 135 --- Training Accuracy:  96.1%, Validation Accuracy:  51.2%,  Validation Loss: 1.909
26130
Training Epoch 136 --- Training Accuracy:  95.3%, Validation Accuracy:  51.2%,  Validation Loss: 1.921
26325
Training Epoch 137 --- Training Accuracy:  96.9%, Validation Accuracy:  51.0%,  Validation Loss: 1.921
26520
Training Epoch 138 --- Training Accuracy:  93.8%, Validation Accuracy:  51.2%,  Validation Loss: 1.916
26715
Training Epoch 139 --- Training Accuracy:  95.7%, Validation Accuracy:  51.6%,  Validation Loss: 1.911
26910
Training Epoch 140 --- Training Accuracy:  96.1%, Validation Accuracy:  50.8%,  Validation Loss: 1.917
27105
Training Epoch 141 --- Training Accuracy:  94.1%, Validation Accuracy:  52.1%,  Validation Loss: 1.893
27300
Training Epoch 142 --- Training Accuracy:  93.4%, Validation Accuracy:  52.5%,  Validation Loss: 1.902
27495
Training Epoch 143 --- Training Accuracy:  94.1%, Validation Accuracy:  51.5%,  Validation Loss: 1.907
27690
Training Epoch 144 --- Training Accuracy:  95.3%, Validation Accuracy:  52.1%,  Validation Loss: 1.907
27885
Training Epoch 145 --- Training Accuracy:  96.1%, Validation Accuracy:  51.7%,  Validation Loss: 1.921
28080
Training Epoch 146 --- Training Accuracy:  96.5%, Validation Accuracy:  52.2%,  Validation Loss: 1.906
28275
Training Epoch 147 --- Training Accuracy:  95.7%, Validation Accuracy:  50.2%,  Validation Loss: 1.926
28470
Training Epoch 148 --- Training Accuracy:  96.9%, Validation Accuracy:  51.3%,  Validation Loss: 1.920
28665
Training Epoch 149 --- Training Accuracy:  97.3%, Validation Accuracy:  50.8%,  Validation Loss: 1.914
28860
Training Epoch 150 --- Training Accuracy:  95.7%, Validation Accuracy:  51.0%,  Validation Loss: 1.923
29055
Training Epoch 151 --- Training Accuracy:  96.5%, Validation Accuracy:  51.1%,  Validation Loss: 1.916
29250
Training Epoch 152 --- Training Accuracy:  96.9%, Validation Accuracy:  50.7%,  Validation Loss: 1.926
29445
Training Epoch 153 --- Training Accuracy:  95.3%, Validation Accuracy:  51.0%,  Validation Loss: 1.912
29640
Training Epoch 154 --- Training Accuracy:  96.9%, Validation Accuracy:  50.8%,  Validation Loss: 1.917
29835
Training Epoch 155 --- Training Accuracy:  97.7%, Validation Accuracy:  51.3%,  Validation Loss: 1.921
30030
Training Epoch 156 --- Training Accuracy:  98.0%, Validation Accuracy:  50.9%,  Validation Loss: 1.920
30225
Training Epoch 157 --- Training Accuracy:  95.7%, Validation Accuracy:  51.6%,  Validation Loss: 1.910
30420
Training Epoch 158 --- Training Accuracy:  95.7%, Validation Accuracy:  50.7%,  Validation Loss: 1.919
30615
Training Epoch 159 --- Training Accuracy:  96.1%, Validation Accuracy:  51.2%,  Validation Loss: 1.920
30810
Training Epoch 160 --- Training Accuracy:  95.7%, Validation Accuracy:  51.6%,  Validation Loss: 1.924
31005
Training Epoch 161 --- Training Accuracy:  96.5%, Validation Accuracy:  52.2%,  Validation Loss: 1.916
31200
Training Epoch 162 --- Training Accuracy:  96.9%, Validation Accuracy:  50.8%,  Validation Loss: 1.916
31395
Training Epoch 163 --- Training Accuracy:  96.9%, Validation Accuracy:  51.2%,  Validation Loss: 1.925
31590
Training Epoch 164 --- Training Accuracy:  95.7%, Validation Accuracy:  49.5%,  Validation Loss: 1.933
31785
Training Epoch 165 --- Training Accuracy:  96.1%, Validation Accuracy:  50.6%,  Validation Loss: 1.930
31980
Training Epoch 166 --- Training Accuracy:  96.9%, Validation Accuracy:  51.6%,  Validation Loss: 1.923
32175
Training Epoch 167 --- Training Accuracy:  96.1%, Validation Accuracy:  50.3%,  Validation Loss: 1.919
32370
Training Epoch 168 --- Training Accuracy:  95.3%, Validation Accuracy:  52.3%,  Validation Loss: 1.907
32565
Training Epoch 169 --- Training Accuracy:  96.5%, Validation Accuracy:  51.2%,  Validation Loss: 1.914
32760
Training Epoch 170 --- Training Accuracy:  98.0%, Validation Accuracy:  50.8%,  Validation Loss: 1.918
32955
Training Epoch 171 --- Training Accuracy:  96.1%, Validation Accuracy:  51.7%,  Validation Loss: 1.909
33150
Training Epoch 172 --- Training Accuracy:  95.7%, Validation Accuracy:  51.7%,  Validation Loss: 1.906
33345
Training Epoch 173 --- Training Accuracy:  96.9%, Validation Accuracy:  50.0%,  Validation Loss: 1.929
33540
Training Epoch 174 --- Training Accuracy:  96.9%, Validation Accuracy:  50.8%,  Validation Loss: 1.922
33735
Training Epoch 175 --- Training Accuracy:  96.5%, Validation Accuracy:  50.2%,  Validation Loss: 1.915
33930
Training Epoch 176 --- Training Accuracy:  97.7%, Validation Accuracy:  52.6%,  Validation Loss: 1.898
34125
Training Epoch 177 --- Training Accuracy:  98.0%, Validation Accuracy:  50.6%,  Validation Loss: 1.915
34320
Training Epoch 178 --- Training Accuracy:  96.1%, Validation Accuracy:  51.8%,  Validation Loss: 1.909
34515
^CTraceback (most recent call last):
  File "cifar_train.py", line 249, in <module>
    train(num_iteration=60000)
  File "cifar_train.py", line 237, in train
    session.run(optimizer, feed_dict=feed_dict_tr)
  File "/home/sid/python3_tf/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 895, in run
    run_metadata_ptr)
  File "/home/sid/python3_tf/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 1128, in _run
    feed_dict_tensor, options, run_metadata)
  File "/home/sid/python3_tf/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 1344, in _do_run
    options, run_metadata)
  File "/home/sid/python3_tf/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 1350, in _do_call
    return fn(*args)
  File "/home/sid/python3_tf/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 1329, in _run_fn
    status, run_metadata)
KeyboardInterrupt
(python3_tf) ]0;sid@blueberry: ~/rddnn[01;32msid@blueberry[00m:[01;34m~/rddnn[00m$ sudo vim cifar_train.py 
[?1049h[?1h=[2;1H▽[6n[2;1H  [1;1H]11;?[1;41r[?12;25h[?12l[?25h[27m[23m[m[H[2J[?25l[41;1H"cifar_train.py" 250L, 8288C[>c[1;1H[35mimport[m dataset
[35mimport[m tensorflow [38;5;130mas[m tf
[35mimport[m time
[35mfrom[m datetime [35mimport[m timedelta
[35mimport[m math
[35mimport[m random
[35mimport[m numpy [38;5;130mas[m np
[35mimport[m sys

[34m#Adding Seed so that random initialization is consistent[m
[35mfrom[m numpy.random [35mimport[m seed
seed([31m1[m)
[35mfrom[m tensorflow [35mimport[m set_random_seed
set_random_seed([31m2[m)

batch_size = [31m256[m
val_batch_size = [31m2000[m

[34m#Prepare input data[m
classes = [[31m'airplane'[m, [31m'automobile'[m,[31m'bird'[m,[31m'cat'[m,[31m'deer'[m,[31m'dog'[m,[31m'frog'[m,[31m'horse'[m,[31m'ship'[m,,[21;1H[31m'truck'[m]
num_classes = [36mlen[m(classes)

img_size = [31m32[m
num_channels = [31m3[m
train_path=[31m"train_dir"[m
val_path = [31m"validation_dir"[m

[34m# We shall load all the training and validation images and labels into memory using  [30;1HopenCV and use that during training[m
data = dataset.read_train_sets(train_path, val_path, img_size, classes)


[36mprint[m([31m"Complete reading input data. Will Now print a snippet of it"[m)
[36mprint[m([31m"Number of files in Training-set:[m[35m\t\t[m[31m{}"[m.format([36mlen[m(data.train.labels)))
[36mprint[m([31m"Number of files in Validation-set:[m[35m\t[m[31m{}"[m.format([36mlen[m(data.valid.labels)))

session = tf.Session()
x = tf.placeholder(tf.float32, shape=[[36mNone[m, img_size,img_size,num_channels], name=[31m'xx[40;1H'[m)[41;67H1,1[11CTop[1;1H[?12l[?25h[?25l[41;67H2[2;1H[?12l[?25h[?25l[41;67H3[3;1H[?12l[?25h[?25l[41;67H4[4;1H[?12l[?25h[?25l[41;67H5[5;1H[?12l[?25h[?25l[41;67H6[6;1H[?12l[?25h[?25l[41;67H7[7;1H[?12l[?25h[?25l[41;67H8[8;1H[?12l[?25h[?25l[41;67H9,0-1[9;1H[?12l[?25h[?25l[41;67H10,1 [10;1H[?12l[?25h[?25l[41;68H1[11;1H[?12l[?25h[?25l[41;68H2[12;1H[?12l[?25h[?25l[41;68H3[13;1H[?12l[?25h[?25l[41;68H4[14;1H[?12l[?25h[?25l[41;68H5,0-1[15;1H[?12l[?25h[?25l[41;68H6,1  [16;1H[?12l[?25h[?25l[41;68H7[17;1H[?12l[?25h[?25l[41;68H8,0-1[18;1H[?12l[?25h[?25l[41;68H9,1  [19;1H[?12l[?25h[?25l[41;67H20[20;1H[?12l[?25h[?25l[41;68H1[22;1H[?12l[?25h[?25l[41;68H2,0-1[23;1H[?12l[?25h[?25l[41;68H3,1  [24;1H[?12l[?25h[?25l[41;68H4[25;1H[?12l[?25h[?25l[41;68H5[26;1H[?12l[?25h[?25l[41;68H6[27;1H[?12l[?25h[?25l[41;68H7,0-1[28;1H[?12l[?25h[?25l[41;68H8,1  [29;1H[?12l[?25h[?25l[41;68H9[31;1H[?12l[?25h[?25l[41;67H30,0-1[32;1H[?12l[?25h[?25l[41;68H1[33;1H[?12l[?25h[?25l[41;68H2,1  [34;1H[?12l[?25h[?25l[41;68H3[35;1H[?12l[?25h[?25l[41;68H4[36;1H[?12l[?25h[?25l[41;68H5,0-1[37;1H[?12l[?25h[?25l[41;68H6,1  [38;1H[?12l[?25h[?25l[41;68H7[39;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[41;1H[K[41;67H38,0-1[9C0%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1H[34m## labels[m[41;67H[K[41;67H39,1[11C0%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1Hy_true = tf.placeholder(tf.float32, shape=[[36mNone[m, num_classes], name=[31m'y_true'[m)[41;67H[K[41;67H40,1[11C1%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1Hy_true_cls = tf.argmax(y_true, dimension=[31m1[m)[41;67H[K[41;67H41,1[11C1%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[41;67H[K[41;67H42,0-1[9C2%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1H[34m##Network graph params[m[41;67H[K[41;67H43,1[11C2%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1Hfc1_layer_size = [31m1024[m[41;67H[K[41;67H44,1[11C3%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1Hfc2_layer_size = [31m1024[m[41;67H[K[41;67H45,1[11C3%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1Hfc3_layer_size = [31m1024[m[41;67H[K[41;67H46,1[11C4%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1Hfc4_layer_size = [31m1024[m[41;67H[K[41;67H47,1[11C4%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1Hfc5_layer_size = [31m1024[m[41;67H[K[41;67H48,1[11C5%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1Hfc6_layer_size = [31m1024[m[41;67H[K[41;67H49,1[11C5%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1Hfc7_layer_size = [31m1024[m[41;67H[K[41;67H50,1[11C6%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1Hfc8_layer_size = [31m1024[m[41;67H[K[41;67H51,1[11C6%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1H[31m'''[m[41;67H[K[41;67H52,1[11C7%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1H[31mfc9_layer_size = 512[m[41;67H[K[41;67H53,1[11C7%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1H[31mfc10_layer_size = 512[m[41;67H[K[41;67H54,1[11C7%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1H[31mfc11_layer_size = 1024[m[41;67H[K[41;67H55,1[11C8%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1H[31mfc12_layer_size = 1024[m[41;67H[K[41;67H56,1[11C8%[40;1H[?12l[?25h[?25l[1;40r[1;1H[2M[1;41r[39;1H[31m'''[m[41;67H[K[41;67H57,1[11C9%[39;1H[?12l[?25h[?25l[41;68H8,0-1[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1H[38;5;130mdef[m [36mcreate_weights[m(shape, name):[41;67H[K[41;67H59,1[11C9%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;5H[38;5;130mreturn[m tf.Variable(tf.truncated_normal(shape, stddev=[31m0.05[m), name=name)[41;67H[K[41;67H60,1[10C10%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[41;67H[K[41;67H61,0-1[8C10%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1H[38;5;130mdef[m [36mcreate_biases[m(size, name):[41;67H[K[41;67H62,1[10C11%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;5H[38;5;130mreturn[m tf.Variable(tf.constant([31m0.05[m, shape=[size]), name=name)[41;67H[K[41;67H63,1[10C11%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[41;67H[K[41;67H64,0-1[8C12%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1H[34m# First layer must be a flatten layer[m[41;67H[K[41;67H65,1[10C12%[40;1H[?12l[?25h[?25l[1;40r[1;1H[2M[1;41r[39;1H[38;5;130mdef[m [36mcreate_flatten_layer[m([36minput[m, batch_size, img_size, num_channels):
    [34m#We know that the shape of the layer will be [batch_size img_size img_size num_c[m[40;1H[94m@                                                                                   [m[41;67H[K[41;67H66,1[10C13%[39;1H[?12l[?25h[?25l[41;68H5[38;1H[?12l[?25h[?25l[41;68H4,0-1[37;1H[?12l[?25h[?25l[41;68H3,1  [36;1H[?12l[?25h[?25l[41;68H2[35;1H[?12l[?25h[?25l[41;68H1,0-1[34;1H[?12l[?25h[?25l[41;68H0,1  [33;1H[?12l[?25h[?25l[41;67H59[32;1H[?12l[?25h[?25l[41;68H8,0-1[31;1H[?12l[?25h[?25l[41;68H7,1  [30;1H[?12l[?25h[?25l[41;68H6[29;1H[?12l[?25h[?25l[41;68H5[28;1H[?12l[?25h[?25l[41;68H4[27;1H[?12l[?25h[?25l[41;68H3[26;1H[?12l[?25h[?25l[41;68H2[25;1H[?12l[?25h[?25l[41;68H1[24;1H[?12l[?25h[?25l[41;68H2[25;1H[?12l[?25h[?25l[41;68H3[26;1H[?12l[?25h[?25l[41;68H4[27;1H[?12l[?25h[?25l[41;68H5[28;1H[?12l[?25h[?25l[41;68H6[29;1H[?12l[?25h[?25l[41;68H7[30;1H[?12l[?25h[?25l[41;68H8,0-1[31;1H[?12l[?25h[?25l[41;68H9,1  [32;1H[?12l[?25h[?25l[41;67H60[33;1H[?12l[?25h[?25l[41;68H1,0-1[34;1H[?12l[?25h[?25l[41;68H2,1  [35;1H[?12l[?25h[?25l[41;68H3[36;1H[?12l[?25h[?25l[41;68H4,0-1[37;1H[?12l[?25h[?25l[41;68H5,1  [38;1H[?12l[?25h[?25l[41;68H6[39;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[39;1H    [34m#We know that the shape of the layer will be [batch_size img_size img_size num_cc[40;1Hhannels] [m[41;67H[K[41;67H67,1[10C13%[39;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;5H[34m# But let's get it from the previous layer.[m[41;67H[K[41;67H68,1[10C14%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;5H[34m#layer_shape = layer.get_shape()[m[41;67H[K[41;67H69,1[10C14%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;5Hlayer_shape = [batch_size, img_size, img_size, num_channels][41;67H[K[41;67H70,1[10C15%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[41;67H[K[41;67H71,0-1[8C15%[40;1H[?12l[?25h[?25l[1;40r[1;1H[2M[1;41r[39;5H[34m## Number of features will be img_height * img_width* num_channels. But we shalll[40;1H calculate it in place of hard-coding it.[m[41;67H[K[41;67H72,1[10C16%[39;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;5H[34m#num_features = layer_shape[1:4].num_elements()[m[41;67H[K[41;67H73,1[10C16%[40;1H[?12l[?25h[?25l[1;40r[1;1H[2M[1;41r[39;5Hnum_features = img_size * img_size * num_channels[41;67H[K[41;67H74,1[10C17%[39;1H[?12l[?25h[?25l[41;68H5,0-1[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;5H[34m## Now, we Flatten the layer so we shall have to reshape to num_features[m[41;67H[K[41;67H76,1[10C17%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;5Hlayer = tf.reshape([36minput[m, [-[31m1[m, num_features])[41;67H[K[41;67H77,1[10C18%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[41;67H[K[41;67H78,0-1[8C18%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;5H[38;5;130mreturn[m layer[41;67H[K[41;67H79,1[10C19%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[41;67H[K[41;67H80,0-1[8C19%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1H[38;5;130mdef[m [36mcreate_fc_layer[m([36minput[m,[41;67H[K[41;67H81,1[10C20%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;14Hnum_inputs,[41;67H[K[41;67H82,1[10C20%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;14Hnum_outputs,[41;67H[K[41;67H83,1[10C21%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;14Hidentifier,[41;67H[K[41;67H84,1[10C21%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;14Huse_relu=[36mTrue[m,[41;67H[K[41;67H85,1[10C22%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;14Hdropout=[36mFalse[m,[41;67H[K[41;67H86,1[10C22%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;14Hdropout_rate=[31m0[m):[41;67H[K[41;67H87,1[10C23%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[41;67H[K[41;67H88,1[10C23%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;5Htoken_weights = identifier + [31m"_weights"[m[41;67H[K[41;67H89,1[10C24%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;5Htoken_bias = identifier + [31m"_bias"[m[41;67H[K[41;67H90,1[10C24%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;5H[34m#Let's define trainable weights and biases.[m[41;67H[K[41;67H91,1[10C25%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;5Hweights = create_weights(shape=[num_inputs, num_outputs], name=token_weights)[41;67H[K[41;67H92,1[10C25%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;5Hbiases = create_biases(num_outputs, name=token_bias)[41;67H[K[41;67H93,1[10C25%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[41;67H[K[41;67H94,0-1[8C26%[40;1H[?12l[?25h[?25l[1;40r[1;1H[2M[1;41r[39;5H[34m# Fully connected layer takes input x and produces wx+b.Since, these are matricee[40;1Hs, we use matmul function in Tensorflow[m[41;67H[K[41;67H95,1[10C27%[39;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;5Hlayer = tf.matmul([36minput[m, weights) + biases[41;67H[K[41;67H96,1[10C27%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[41;67H[K[41;67H97,1[10C28%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;5H[38;5;130mif[m use_relu:[41;67H[K[41;67H98,1[10C28%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;9Hlayer = tf.nn.relu(layer)[41;67H[K[41;67H99,1[10C29%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;5H[38;5;130melse[m:[41;67H[K[41;67H100,1[9C29%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;9Hlayer = tf.nn.sigmoid(layer)[41;67H[K[41;67H101,1[9C30%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[41;67H[K[41;67H102,0-1[7C30%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;5H[38;5;130mif[m dropout:[41;67H[K[41;67H103,1[9C30%[40;1H[?12l[?25h[?25l[1;40r[1;1H[2M[1;41r[39;9Hlayer = tf.layers.dropout(layer, rate=dropout_rate, training=[36mTrue[m)[41;67H[K[41;67H104,1[9C31%[39;1H[?12l[?25h[?25l[41;69H5,0-1[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;5H[38;5;130mreturn[m layer[41;67H[K[41;67H106,1[9C32%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[41;67H[K[41;67H107,0-1[7C32%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1Hflatten = create_flatten_layer(x, batch_size, img_size, num_channels)[41;67H[K[41;67H108,1[9C33%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[41;67H[K[41;67H109,0-1[7C33%[40;1H[?12l[?25h[?25l[1;40r[1;1H[2M[1;41r[39;1H[34m# fc1_layer_size neurons with relu activation[m
layer_fc1 = create_fc_layer([36minput[m=flatten,[41;67H[K[41;67H110,1[9C34%[39;1H[?12l[?25h[?25l[41;69H1[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;22Hnum_inputs=img_size*img_size*num_channels,[41;67H[K[41;67H112,1[9C34%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;22Hnum_outputs=fc1_layer_size,[41;67H[K[41;67H113,1[9C35%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;22Hidentifier=[31m"fc1"[m)[41;67H[K[41;67H114,1[9C35%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[41;67H[K[41;67H115,0-1[7C36%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1Hlayer_fc2 = create_fc_layer([36minput[m=layer_fc1,[41;67H[K[41;67H116,1[9C36%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;22Hnum_inputs=fc1_layer_size,[41;67H[K[41;67H117,1[9C36%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;22Hnum_outputs=fc2_layer_size,[41;67H[K[41;67H118,1[9C37%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;18Hidentifier=[31m"fc2"[m,[41;67H[K[41;67H119,1[9C37%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;25Hdropout=[36mFalse[m,[41;67H[K[41;67H120,1-8[7C38%[40;8H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;25Hdropout_rate=[31m0.3[m)[41;67H[K[41;67H121,1-8[7C38%[40;8H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[41;67H[K[41;67H122,0-1[7C39%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1Hlayer_fc3 = create_fc_layer([36minput[m=layer_fc2,[41;67H[K[41;67H123,1[9C39%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;22Hnum_inputs=fc2_layer_size,[41;67H[K[41;67H124,1[9C40%[40;1H[?12l[?25h[?25l[41;69H3[39;1H[?12l[?25h[?25l[41;69H2,0-1[38;1H[?12l[?25h[?25l[41;69H1,1-8[37;8H[?12l[?25h[?25l[41;69H0[36;8H[?12l[?25h[?25l[41;68H19,1  [35;1H[?12l[?25h[?25l[41;69H8[34;1H[?12l[?25h[?25l[41;69H7[33;1H[?12l[?25h[?25l[41;69H6[32;1H[?12l[?25h[?25l[41;69H5,0-1[31;1H[?12l[?25h[?25l[41;69H6,1  [32;1H[?12l[?25h[?25l[41;69H7[33;1H[?12l[?25h[?25l[41;69H8[34;1H[?12l[?25h[?25l[41;69H9[35;1H[?12l[?25h[?25l[41;68H20,1-8[36;8H[?12l[?25h[?25l[41;69H1[37;8H[?12l[?25h[?25l[41;69H0[36;8H[?12l[?25h[?25l[41;72H7-38[36;38H[?12l[?25h[?25l[41;72H6-37[36;37H[?12l[?25h[?25l[41;72H7-38[36;38H[?12l[?25h[?25l[41;72H6-37[36;37H[?12l[?25h[?25l[41;72H5-36[36;36H[?12l[?25h[?25l[41;72H4-35[36;35H[?12l[?25h[?25l[41;72H3-34[36;34H[?12l[?25h[?25l[41;72H4-35[36;35H[?12l[?25h[?25l[41;72H5-36[36;36H[?12l[?25h[?25l[41;72H6-37[36;37H[?12l[?25h[?25l[41;72H7-38[36;38H[?12l[?25h[?25l[41;1H[1m-- INSERT --[m[41;67H[K[41;67H120,17-38     40%[36;38H[?12l[?25h[?25lFals,[36;38H[K[41;72H6-37[36;37H[?12l[?25h[?25l,[36;37H[K[41;72H5-36[36;36H[?12l[?25h[?25l,[36;36H[K[41;72H4-35[36;35H[?12l[?25h[?25l,[36;35H[K[41;72H3-34[36;34H[?12l[?25h[?25l,[36;34H[K[41;72H2-33[36;33H[?12l[?25h[?25lT,[41;72H3-34[36;34H[?12l[?25h[?25lr,[41;72H4-35[36;35H[?12l[?25h[?25lu,[41;72H5-36[36;36H[?12l[?25h[?25l[36mTrue[m,[41;72H6-37[36;37H[?12l[?25h[?25l[41;69H1[37;37H[?12l[?25h[?25l[41;69H2,1    [38;1H[?12l[?25h[?25l[41;69H4,37[40;37H[?12l[?25h[?25l[1;40r[1;1H[2M[1;41r[39;22Hnum_outputs=fc3_layer_size,[40;22Hidentifier=[31m"fc3"[m,[41;67H[K[41;67H126,37[8C41%[40;37H[?12l[?25h[?25l[1;40r[1;1H[2M[1;41r[39;25Hdropout=[36mFalse[m,[40;25Hdropout_rate=[31m0.3[m)[41;67H[K[41;67H128,16-37     42%[40;37H[?12l[?25h[?25l[1;40r[1;1H[2M[1;41r[40;1Hlayer_fc4 = create_fc_layer([36minput[m=layer_fc3,[41;67H[K[41;67H130,37[8C43%[40;37H[?12l[?25h[?25l[1;40r[1;1H[2M[1;41r[39;22Hnum_inputs=fc3_layer_size,[40;22Hnum_outputs=fc4_layer_size,[41;67H[K[41;67H132,37[8C44%[40;37H[?12l[?25h[?25l[1;40r[1;1H[3M[1;41r[38;22Hidentifier=[31m"fc4"[m,[39;25Hdropout=[36mFalse[m,[40;25Hdropout_rate=[31m0.3[m)[41;67H[K[41;67H134,16-37     45%[39;37H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[41;67H[K[41;67H136,1[9C45%[40;1H[?12l[?25h[?25l[1;40r[1;1H[2M[1;41r[39;1H[34m#layer_fc4 = layer_fc2 + layer_fc4[m[41;67H[K[41;67H138,1[9C46%[40;1H[?12l[?25h[?25l[1;40r[1;1H[2M[1;41r[39;1Hlayer_fc5 = create_fc_layer([36minput[m=layer_fc4,[40;22Hnum_inputs=fc4_layer_size,[41;67H[K[41;67H140,37[8C47%[40;37H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;22Hnum_outputs=fc5_layer_size,[41;67H[K[41;67H141,37[8C48%[40;37H[?12l[?25h[?25l[41;69H0[39;37H[?12l[?25h[?25l[41;68H39[38;37H[?12l[?25h[?25l[41;69H5,16-37[34;37H[?12l[?25h[?25l[41;69H3,37   [32;37H[?12l[?25h[?25l[41;69H1[30;37H[?12l[?25h[?25l[41;68H29,1 [28;1H[?12l[?25h[?25l[41;69H7,16-37[26;37H[?12l[?25h[?25l[41;69H6,37   [25;37H[?12l[?25h[?25l[41;69H4[23;37H[?12l[?25h[?25l[41;69H5[24;37H[?12l[?25h[?25l[41;69H6[25;37H[?12l[?25h[?25l[41;69H7,16-37[26;37H[?12l[?25h[?25l[41;72H7-38[26;38H[?12l[?25h[?25lFals,[26;38H[K[41;72H6-37[26;37H[?12l[?25h[?25l,[26;37H[K[41;72H5-36[26;36H[?12l[?25h[?25l,[26;36H[K[41;72H4-35[26;35H[?12l[?25h[?25l,[26;35H[K[41;72H3-34[26;34H[?12l[?25h[?25l,[26;34H[K[41;72H2-33[26;33H[?12l[?25h[?25lT,[41;72H3-34[26;34H[?12l[?25h[?25lr,[41;72H4-35[26;35H[?12l[?25h[?25lu,[41;72H5-36[26;36H[?12l[?25h[?25l[36mTrue[m,[41;72H6-37[26;37H[?12l[?25h[?25l[41;69H8[27;37H[?12l[?25h[?25l[41;69H9,1    [28;1H[?12l[?25h[?25l[41;68H30,37[29;37H[?12l[?25h[?25l[41;69H1[30;37H[?12l[?25h[?25l[41;69H2[31;37H[?12l[?25h[?25l[41;69H3[32;37H[?12l[?25h[?25l[41;69H4,16-37[33;37H[?12l[?25h[?25l[41;72H7-38[33;38H[?12l[?25h[?25lFals,[33;38H[K[41;72H6-37[33;37H[?12l[?25h[?25l,[33;37H[K[41;72H5-36[33;36H[?12l[?25h[?25l,[33;36H[K[41;72H4-35[33;35H[?12l[?25h[?25l,[33;35H[K[41;72H3-34[33;34H[?12l[?25h[?25l,[33;34H[K[41;72H2-33[33;33H[?12l[?25h[?25lT,[41;72H3-34[33;34H[?12l[?25h[?25lr,[41;72H4-35[33;35H[?12l[?25h[?25lu,[41;72H5-36[33;36H[?12l[?25h[?25l[36mTrue[m,[41;72H6-37[33;37H[?12l[?25h[?25l[41;69H5[34;37H[?12l[?25h[?25l[41;69H6,1    [35;1H[?12l[?25h[?25l[41;69H8[37;1H[?12l[?25h[?25l[41;68H40,37[39;37H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;22Hidentifier=[31m"fc5"[m,[41;67H[K[41;67H142,37[8C48%[40;37H[?12l[?25h[?25l[1;40r[1;1H[2M[1;41r[39;25Hdropout=[36mFalse[m,[40;25Hdropout_rate=[31m0.3[m)[41;67H[K[41;67H144,16-37     49%[40;37H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[41;67H[K[41;67H145,1[9C50%[40;1H[?12l[?25h[?25l[1;40r[1;1H[3M[1;41r[38;1Hlayer_fc6 = create_fc_layer([36minput[m=layer_fc5,[39;22Hnum_inputs=fc5_layer_size,[40;22Hnum_outputs=fc6_layer_size,[41;67H[K[41;67H148,37[8C51%[40;37H[?12l[?25h[?25l[1;40r[1;1H[2M[1;41r[39;22Hidentifier=[31m"fc6"[m,[40;25Hdropout=[36mFalse[m,[41;67H[K[41;67H150,16-37     52%[40;37H[?12l[?25h[?25l[1;40r[1;1H[2M[1;41r[39;25Hdropout_rate=[31m0.3[m)[41;67H[K[41;67H152,1[9C53%[40;1H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;1Hlayer_fc7 = create_fc_layer([36minput[m=layer_fc6,[41;67H[K[41;67H153,37[8C53%[40;37H[?12l[?25h[?25l[1;40r[40;1H
[1;41r[40;22Hnum_inputs=fc6_layer_size,[41;67H[K[41;67H154,37[8C54%[40;37H[?12l[?25h[?25l[41;69H3[39;37H[?12l[?25h[?25l[41;69H2,1 [38;1H[?12l[?25h[?25l[41;69H1,16-37[37;37H[?12l[?25h[?25l[41;69H0[36;37H[?12l[?25h[?25l[41;72H7-38[36;38H[?12l[?25h[?25lFals,[36;38H[K[41;72H6-37[36;37H[?12l[?25h[?25l,[36;37H[K[41;72H5-36[36;36H[?12l[?25h[?25l,[36;36H[K[41;72H4-35[36;35H[?12l[?25h[?25l,[36;35H[K[41;72H3-34[36;34H[?12l[?25h[?25l,[36;34H[K[41;72H2-33[36;33H[?12l[?25h[?25lT,[41;72H3-34[36;34H[?12l[?25h[?25lr,[41;72H4-35[36;35H[?12l[?25h[?25lu,[41;72H5-36[36;36H[?12l[?25h[?25l[36mTrue[m,[41;72H6-37[36;37H[?12l[?25h[?25l[41;68H49,37   [35;37H[?12l[?25h[?25l[41;69H8[34;37H[?12l[?25h[?25l[41;69H7[33;37H[?12l[?25h[?25l[41;69H6[32;37H[?12l[?25h[?25l[41;69H5,1 [31;1H[?12l[?25h[?25l[41;69H4,16-37[30;37H[?12l[?25h[?25l[41;69H3[29;37H[?12l[?25h[?25l[41;69H2,37   [28;37H[?12l[?25h[?25l[41;69H3,16-37[29;37H[?12l[?25h[?25l[41;72H7-38[29;38H[?12l[?25h[?25lFals,[29;38H[K[41;72H6-37[29;37H[?12l[?25h[?25l,[29;37H[K[41;72H5-36[29;36H[?12l[?25h[?25l,[29;36H[K[41;72H4-35[29;35H[?12l[?25h[?25l,[29;35H[K[41;72H3-34[29;34H[?12l[?25h[?25l,[29;34H[K[41;72H2-33[29;33H[?12l[?25h[?25lT,[41;72H3-34[29;34H[?12l[?25h[?25lr,[41;72H4-35[29;35H[?12l[?25h[?25l[36mTrue[m,[41;72H6-37[29;37H[?12l[?25h[?25l[41;69H4[30;37H[?12l[?25h[?25l[41;69H5,1    [31;1H[?12l[?25h[?25l[41;69H9,37[35;37H[?12l[?25h[?25l[41;68H51,16-37[37;37H[?12l[?25h[?25l[1;40r[1;1H[6M[1;41r[35;22Hnum_outputs=fc7_layer_size,[36;25Hdropout=[36mFalse[m,[37;25Hdropout_rate=[31m0.3[m,[38;22Hidentifier=[31m"fc7"[m)

layer_fc8 = create_fc_layer([36minput[m=layer_fc7,[41;67H[K[41;67H160,37[8C57%[40;37H[?12l[?25h[?25l[1;40r[1;1H[2M[1;41r[39;22Hnum_inputs=fc7_layer_size,[40;22Hnum_outputs=num_classes,[41;67H[K[41;67H162,37[8C58%[40;37H[?12l[?25h[?25l[1;40r[1;1H[2M[1;41r[39;22Hidentifier=[31m"fc8"[m,[40;25Huse_relu=[36mFalse[m)[41;67H[K[41;67H164,16-37     59%[40;37H[?12l[?25h[?25l[1;40r[1;1H[2M[1;41r[39;1H[31m'''
layer_fc9 = create_fc_layer(input=layer_fc8,[m[41;67H[K[41;67H166,37[8C60%[40;37H[?12l[?25h[?25l[1;40r[1;1H[2M[1;41r[39;1H[31m                     num_inputs=fc8_layer_size,
                     num_outputs=fc9_layer_size,[m[41;67H[K[41;67H168,37[8C60%[40;37H[?12l[?25h[?25l[1;40r[1;1H[2M[1;41r[39;1H[31m                     identifier="fc9",
                dropout=True,[m[41;67H[K[41;67H170,16-30     61%[40;30H[?12l[?25h[?25l[1;40r[1;1H[2M[1;41r[39;1H[31m                dropout_rate=0.5)[m[41;67H[K[41;67H172,1[9C62%[40;1H[?12l[?25h[?25l[34;28H[31m[106m([39;33H)[m[41;69H1,20-34[39;34H[?12l[?25h[?25l[34;28H[31m([39;33H)[m[41;69H0,16-30[38;30H[?12l[?25h[?25l[41;68H68,37   [36;37H[?12l[?25h[?25l[41;69H7[35;37H[?12l[?25h[?25l[41;69H5,4 [33;4H[?12l[?25h[?25l[41;69H3,37[31;37H[?12l[?25h[?25l[41;69H1[29;37H[?12l[?25h[?25l[41;69H0[28;37H[?12l[?25h[?25l[41;68H59,1 [27;1H[?12l[?25h[?25l[41;69H8,37[26;37H[?12l[?25h[?25l[41;69H7,16-37[25;37H[?12l[?25h[?25l[41;69H6[24;37H[?12l[?25h[?25l[41;72H7-38[24;38H[?12l[?25h[?25lFals,[24;38H[K[41;72H6-37[24;37H[?12l[?25h[?25l,[24;37H[K[41;72H5-36[24;36H[?12l[?25h[?25l,[24;36H[K[41;72H4-35[24;35H[?12l[?25h[?25l,[24;35H[K[41;72H3-34[24;34H[?12l[?25h[?25l,[24;34H[K[41;72H2-33[24;33H[?12l[?25h[?25lT,[41;72H3-34[24;34H[?12l[?25h[?25lr,[41;72H4-35[24;35H[?12l[?25h[?25lu,[41;72H5-36[24;36H[?12l[?25h[?25l[36mTrue[m,[41;72H6-37[24;37H[?12l[?25h[?25l[41;69H7[25;37H[?12l[?25h[?25l[41;69H8,37   [26;37H[?12l[?25h[41;1H[K[26;36H[?25l[41;67H158,36[8C62%[26;36H[?12l[?25h[?25l[41;67H[K[41;1H:[?12l[?25hw[?25l[?12l[?25hq[?25l[?12l[?25h[?25l"cifar_train.py" 250L, 8282C written
[?1l>[?12l[?25h[?1049l(python3_tf) ]0;sid@blueberry: ~/rddnn[01;32msid@blueberry[00m:[01;34m~/rddnn[00m$ sudo vim cifar_train.py [2Ppython[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C
/home/sid/python3_tf/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Going to read training images
Now going to read airplane files (Index: 0)
Now going to read automobile files (Index: 1)
Now going to read bird files (Index: 2)
Now going to read cat files (Index: 3)
Now going to read deer files (Index: 4)
Now going to read dog files (Index: 5)
Now going to read frog files (Index: 6)
Now going to read horse files (Index: 7)
Now going to read ship files (Index: 8)
Now going to read truck files (Index: 9)
Going to read training images
Now going to read airplane files (Index: 0)
Now going to read automobile files (Index: 1)
Now going to read bird files (Index: 2)
Now going to read cat files (Index: 3)
Now going to read deer files (Index: 4)
Now going to read dog files (Index: 5)
Now going to read frog files (Index: 6)
Now going to read horse files (Index: 7)
Now going to read ship files (Index: 8)
Now going to read truck files (Index: 9)
Complete reading input data. Will Now print a snippet of it
Number of files in Training-set:		50000
Number of files in Validation-set:	10000
2018-06-01 16:22:30.664549: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-06-01 16:22:30.740120: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-06-01 16:22:30.740324: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: GeForce GTX 1060 6GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:01:00.0
totalMemory: 5.93GiB freeMemory: 5.65GiB
2018-06-01 16:22:30.740336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1)
WARNING:tensorflow:From cifar_train.py:41: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.
Instructions for updating:
Use the `axis` argument instead
WARNING:tensorflow:From cifar_train.py:198: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See tf.nn.softmax_cross_entropy_with_logits_v2.

Training Epoch 1 --- Training Accuracy:  10.9%, Validation Accuracy:   9.8%,  Validation Loss: 2.372
0
Training Epoch 2 --- Training Accuracy:  15.6%, Validation Accuracy:  16.4%,  Validation Loss: 2.162
195
Training Epoch 3 --- Training Accuracy:  17.6%, Validation Accuracy:  17.6%,  Validation Loss: 2.127
390
Training Epoch 4 --- Training Accuracy:  19.5%, Validation Accuracy:  20.6%,  Validation Loss: 2.082
585
Training Epoch 5 --- Training Accuracy:  23.8%, Validation Accuracy:  27.5%,  Validation Loss: 2.041
780
Training Epoch 6 --- Training Accuracy:  26.6%, Validation Accuracy:  29.1%,  Validation Loss: 2.030
975
Training Epoch 7 --- Training Accuracy:  32.4%, Validation Accuracy:  31.0%,  Validation Loss: 1.991
1170
Training Epoch 8 --- Training Accuracy:  32.4%, Validation Accuracy:  34.2%,  Validation Loss: 1.969
1365
Training Epoch 9 --- Training Accuracy:  39.8%, Validation Accuracy:  35.5%,  Validation Loss: 1.954
1560
Training Epoch 10 --- Training Accuracy:  40.2%, Validation Accuracy:  36.3%,  Validation Loss: 1.946
1755
Training Epoch 11 --- Training Accuracy:  40.2%, Validation Accuracy:  36.1%,  Validation Loss: 1.951
1950
Training Epoch 12 --- Training Accuracy:  41.0%, Validation Accuracy:  38.7%,  Validation Loss: 1.939
2145
Training Epoch 13 --- Training Accuracy:  42.6%, Validation Accuracy:  38.4%,  Validation Loss: 1.941
2340
Training Epoch 14 --- Training Accuracy:  42.2%, Validation Accuracy:  38.0%,  Validation Loss: 1.927
2535
Training Epoch 15 --- Training Accuracy:  40.6%, Validation Accuracy:  38.6%,  Validation Loss: 1.929
2730
Training Epoch 16 --- Training Accuracy:  42.2%, Validation Accuracy:  39.1%,  Validation Loss: 1.929
2925
Training Epoch 17 --- Training Accuracy:  40.2%, Validation Accuracy:  39.4%,  Validation Loss: 1.922
3120
Training Epoch 18 --- Training Accuracy:  43.8%, Validation Accuracy:  40.8%,  Validation Loss: 1.911
3315
Training Epoch 19 --- Training Accuracy:  47.3%, Validation Accuracy:  40.5%,  Validation Loss: 1.918
3510
Training Epoch 20 --- Training Accuracy:  43.0%, Validation Accuracy:  41.7%,  Validation Loss: 1.912
3705
Training Epoch 21 --- Training Accuracy:  47.7%, Validation Accuracy:  41.9%,  Validation Loss: 1.912
3900
Training Epoch 22 --- Training Accuracy:  48.4%, Validation Accuracy:  42.2%,  Validation Loss: 1.901
4095
Training Epoch 23 --- Training Accuracy:  46.1%, Validation Accuracy:  41.1%,  Validation Loss: 1.902
4290
Training Epoch 24 --- Training Accuracy:  51.2%, Validation Accuracy:  43.0%,  Validation Loss: 1.894
4485
Training Epoch 25 --- Training Accuracy:  49.2%, Validation Accuracy:  42.4%,  Validation Loss: 1.888
4680
Training Epoch 26 --- Training Accuracy:  50.0%, Validation Accuracy:  41.8%,  Validation Loss: 1.896
4875
Training Epoch 27 --- Training Accuracy:  53.1%, Validation Accuracy:  42.9%,  Validation Loss: 1.878
5070
Training Epoch 28 --- Training Accuracy:  47.7%, Validation Accuracy:  42.1%,  Validation Loss: 1.894
5265
Training Epoch 29 --- Training Accuracy:  46.1%, Validation Accuracy:  43.1%,  Validation Loss: 1.889
5460
Training Epoch 30 --- Training Accuracy:  50.8%, Validation Accuracy:  43.1%,  Validation Loss: 1.892
5655
Training Epoch 31 --- Training Accuracy:  52.3%, Validation Accuracy:  44.2%,  Validation Loss: 1.889
5850
Training Epoch 32 --- Training Accuracy:  55.5%, Validation Accuracy:  44.9%,  Validation Loss: 1.878
6045
Training Epoch 33 --- Training Accuracy:  51.6%, Validation Accuracy:  43.9%,  Validation Loss: 1.878
6240
Training Epoch 34 --- Training Accuracy:  52.7%, Validation Accuracy:  44.8%,  Validation Loss: 1.875
6435
Training Epoch 35 --- Training Accuracy:  52.3%, Validation Accuracy:  44.9%,  Validation Loss: 1.868
6630
Training Epoch 36 --- Training Accuracy:  53.9%, Validation Accuracy:  44.9%,  Validation Loss: 1.877
6825
Training Epoch 37 --- Training Accuracy:  54.3%, Validation Accuracy:  44.1%,  Validation Loss: 1.879
7020
Training Epoch 38 --- Training Accuracy:  51.2%, Validation Accuracy:  45.1%,  Validation Loss: 1.871
7215
Training Epoch 39 --- Training Accuracy:  50.0%, Validation Accuracy:  44.0%,  Validation Loss: 1.869
7410
Training Epoch 40 --- Training Accuracy:  53.5%, Validation Accuracy:  45.6%,  Validation Loss: 1.871
7605
Training Epoch 41 --- Training Accuracy:  52.0%, Validation Accuracy:  43.9%,  Validation Loss: 1.877
7800
Training Epoch 42 --- Training Accuracy:  50.4%, Validation Accuracy:  43.8%,  Validation Loss: 1.888
7995
Training Epoch 43 --- Training Accuracy:  53.1%, Validation Accuracy:  44.9%,  Validation Loss: 1.872
8190
Training Epoch 44 --- Training Accuracy:  53.1%, Validation Accuracy:  46.4%,  Validation Loss: 1.876
8385
Training Epoch 45 --- Training Accuracy:  53.9%, Validation Accuracy:  46.2%,  Validation Loss: 1.869
8580
Training Epoch 46 --- Training Accuracy:  56.6%, Validation Accuracy:  44.2%,  Validation Loss: 1.872
8775
Training Epoch 47 --- Training Accuracy:  54.7%, Validation Accuracy:  44.7%,  Validation Loss: 1.873
8970
Training Epoch 48 --- Training Accuracy:  54.3%, Validation Accuracy:  44.4%,  Validation Loss: 1.865
9165
Training Epoch 49 --- Training Accuracy:  58.6%, Validation Accuracy:  45.0%,  Validation Loss: 1.864
9360
Training Epoch 50 --- Training Accuracy:  55.1%, Validation Accuracy:  45.2%,  Validation Loss: 1.859
9555
Training Epoch 51 --- Training Accuracy:  59.8%, Validation Accuracy:  44.9%,  Validation Loss: 1.875
9750
Training Epoch 52 --- Training Accuracy:  55.5%, Validation Accuracy:  43.8%,  Validation Loss: 1.888
9945
Training Epoch 53 --- Training Accuracy:  55.1%, Validation Accuracy:  44.5%,  Validation Loss: 1.871
10140
Training Epoch 54 --- Training Accuracy:  57.0%, Validation Accuracy:  46.3%,  Validation Loss: 1.865
10335
Training Epoch 55 --- Training Accuracy:  59.0%, Validation Accuracy:  45.7%,  Validation Loss: 1.864
10530
Training Epoch 56 --- Training Accuracy:  56.2%, Validation Accuracy:  44.2%,  Validation Loss: 1.865
10725
Training Epoch 57 --- Training Accuracy:  55.5%, Validation Accuracy:  45.4%,  Validation Loss: 1.857
10920
Training Epoch 58 --- Training Accuracy:  59.8%, Validation Accuracy:  47.2%,  Validation Loss: 1.856
11115
Training Epoch 59 --- Training Accuracy:  56.6%, Validation Accuracy:  46.0%,  Validation Loss: 1.861
11310
Training Epoch 60 --- Training Accuracy:  56.6%, Validation Accuracy:  46.1%,  Validation Loss: 1.872
11505
Training Epoch 61 --- Training Accuracy:  54.3%, Validation Accuracy:  45.1%,  Validation Loss: 1.869
11700
Training Epoch 62 --- Training Accuracy:  54.7%, Validation Accuracy:  46.3%,  Validation Loss: 1.869
11895
Training Epoch 63 --- Training Accuracy:  58.6%, Validation Accuracy:  46.3%,  Validation Loss: 1.866
12090
Training Epoch 64 --- Training Accuracy:  60.2%, Validation Accuracy:  47.8%,  Validation Loss: 1.863
12285
Training Epoch 65 --- Training Accuracy:  59.4%, Validation Accuracy:  45.8%,  Validation Loss: 1.867
12480
Training Epoch 66 --- Training Accuracy:  57.8%, Validation Accuracy:  46.3%,  Validation Loss: 1.860
12675
Training Epoch 67 --- Training Accuracy:  59.8%, Validation Accuracy:  46.8%,  Validation Loss: 1.867
12870
Training Epoch 68 --- Training Accuracy:  60.5%, Validation Accuracy:  45.3%,  Validation Loss: 1.866
13065
Training Epoch 69 --- Training Accuracy:  59.4%, Validation Accuracy:  45.7%,  Validation Loss: 1.873
13260
Training Epoch 70 --- Training Accuracy:  59.0%, Validation Accuracy:  46.5%,  Validation Loss: 1.858
13455
Training Epoch 71 --- Training Accuracy:  58.2%, Validation Accuracy:  45.2%,  Validation Loss: 1.878
13650
Training Epoch 72 --- Training Accuracy:  61.7%, Validation Accuracy:  46.5%,  Validation Loss: 1.856
13845
Training Epoch 73 --- Training Accuracy:  60.5%, Validation Accuracy:  47.0%,  Validation Loss: 1.875
14040
Training Epoch 74 --- Training Accuracy:  59.4%, Validation Accuracy:  45.9%,  Validation Loss: 1.866
14235
Training Epoch 75 --- Training Accuracy:  60.9%, Validation Accuracy:  45.7%,  Validation Loss: 1.865
14430
Training Epoch 76 --- Training Accuracy:  63.3%, Validation Accuracy:  46.2%,  Validation Loss: 1.865
14625
Training Epoch 77 --- Training Accuracy:  59.4%, Validation Accuracy:  43.3%,  Validation Loss: 1.877
14820
Training Epoch 78 --- Training Accuracy:  61.7%, Validation Accuracy:  46.1%,  Validation Loss: 1.860
15015
Training Epoch 79 --- Training Accuracy:  60.9%, Validation Accuracy:  46.4%,  Validation Loss: 1.869
15210
Training Epoch 80 --- Training Accuracy:  64.5%, Validation Accuracy:  47.0%,  Validation Loss: 1.866
15405
Training Epoch 81 --- Training Accuracy:  62.9%, Validation Accuracy:  46.8%,  Validation Loss: 1.860
15600
Training Epoch 82 --- Training Accuracy:  63.7%, Validation Accuracy:  45.5%,  Validation Loss: 1.867
15795
Training Epoch 83 --- Training Accuracy:  61.7%, Validation Accuracy:  46.8%,  Validation Loss: 1.856
15990
Training Epoch 84 --- Training Accuracy:  62.5%, Validation Accuracy:  46.1%,  Validation Loss: 1.851
16185
Training Epoch 85 --- Training Accuracy:  59.4%, Validation Accuracy:  46.7%,  Validation Loss: 1.861
16380
Training Epoch 86 --- Training Accuracy:  64.5%, Validation Accuracy:  44.8%,  Validation Loss: 1.867
16575
Training Epoch 87 --- Training Accuracy:  64.1%, Validation Accuracy:  45.5%,  Validation Loss: 1.862
16770
Training Epoch 88 --- Training Accuracy:  63.3%, Validation Accuracy:  45.7%,  Validation Loss: 1.871
16965
Training Epoch 89 --- Training Accuracy:  63.3%, Validation Accuracy:  46.8%,  Validation Loss: 1.860
17160
Training Epoch 90 --- Training Accuracy:  62.9%, Validation Accuracy:  46.5%,  Validation Loss: 1.866
17355
Training Epoch 91 --- Training Accuracy:  64.1%, Validation Accuracy:  46.3%,  Validation Loss: 1.862
17550
Training Epoch 92 --- Training Accuracy:  64.1%, Validation Accuracy:  48.1%,  Validation Loss: 1.853
17745
Training Epoch 93 --- Training Accuracy:  63.7%, Validation Accuracy:  46.1%,  Validation Loss: 1.860
17940
Training Epoch 94 --- Training Accuracy:  64.8%, Validation Accuracy:  48.5%,  Validation Loss: 1.857
18135
Training Epoch 95 --- Training Accuracy:  64.8%, Validation Accuracy:  46.5%,  Validation Loss: 1.863
18330
Training Epoch 96 --- Training Accuracy:  66.0%, Validation Accuracy:  46.1%,  Validation Loss: 1.878
18525
Training Epoch 97 --- Training Accuracy:  63.7%, Validation Accuracy:  47.2%,  Validation Loss: 1.867
18720
Training Epoch 98 --- Training Accuracy:  61.3%, Validation Accuracy:  46.8%,  Validation Loss: 1.861
18915
Training Epoch 99 --- Training Accuracy:  68.4%, Validation Accuracy:  46.8%,  Validation Loss: 1.859
19110
Training Epoch 100 --- Training Accuracy:  64.1%, Validation Accuracy:  46.3%,  Validation Loss: 1.877
19305
Training Epoch 101 --- Training Accuracy:  66.4%, Validation Accuracy:  47.9%,  Validation Loss: 1.871
19500
Training Epoch 102 --- Training Accuracy:  65.6%, Validation Accuracy:  46.9%,  Validation Loss: 1.866
19695
Training Epoch 103 --- Training Accuracy:  68.8%, Validation Accuracy:  47.0%,  Validation Loss: 1.876
19890
Training Epoch 104 --- Training Accuracy:  62.5%, Validation Accuracy:  47.3%,  Validation Loss: 1.858
20085
Training Epoch 105 --- Training Accuracy:  62.5%, Validation Accuracy:  47.0%,  Validation Loss: 1.869
20280
Training Epoch 106 --- Training Accuracy:  66.8%, Validation Accuracy:  48.3%,  Validation Loss: 1.857
20475
Training Epoch 107 --- Training Accuracy:  64.8%, Validation Accuracy:  47.5%,  Validation Loss: 1.869
20670
Training Epoch 108 --- Training Accuracy:  65.2%, Validation Accuracy:  46.6%,  Validation Loss: 1.876
20865
Training Epoch 109 --- Training Accuracy:  64.1%, Validation Accuracy:  46.6%,  Validation Loss: 1.867
21060
Training Epoch 110 --- Training Accuracy:  60.2%, Validation Accuracy:  47.5%,  Validation Loss: 1.859
21255
Training Epoch 111 --- Training Accuracy:  64.8%, Validation Accuracy:  48.4%,  Validation Loss: 1.859
21450
Training Epoch 112 --- Training Accuracy:  61.7%, Validation Accuracy:  45.4%,  Validation Loss: 1.872
21645
Training Epoch 113 --- Training Accuracy:  66.4%, Validation Accuracy:  47.2%,  Validation Loss: 1.878
21840
Training Epoch 114 --- Training Accuracy:  64.1%, Validation Accuracy:  46.8%,  Validation Loss: 1.869
22035
Training Epoch 115 --- Training Accuracy:  69.9%, Validation Accuracy:  47.0%,  Validation Loss: 1.859
22230
Training Epoch 116 --- Training Accuracy:  68.0%, Validation Accuracy:  47.0%,  Validation Loss: 1.868
22425
Training Epoch 117 --- Training Accuracy:  63.7%, Validation Accuracy:  46.0%,  Validation Loss: 1.871
22620
Training Epoch 118 --- Training Accuracy:  64.8%, Validation Accuracy:  46.8%,  Validation Loss: 1.859
22815
Training Epoch 119 --- Training Accuracy:  67.2%, Validation Accuracy:  47.0%,  Validation Loss: 1.875
23010
Training Epoch 120 --- Training Accuracy:  64.1%, Validation Accuracy:  45.3%,  Validation Loss: 1.878
23205
Training Epoch 121 --- Training Accuracy:  69.1%, Validation Accuracy:  46.4%,  Validation Loss: 1.862
23400
Training Epoch 122 --- Training Accuracy:  70.3%, Validation Accuracy:  47.8%,  Validation Loss: 1.859
23595
Training Epoch 123 --- Training Accuracy:  65.2%, Validation Accuracy:  47.6%,  Validation Loss: 1.871
23790
Training Epoch 124 --- Training Accuracy:  68.4%, Validation Accuracy:  46.3%,  Validation Loss: 1.858
23985
Training Epoch 125 --- Training Accuracy:  67.2%, Validation Accuracy:  47.9%,  Validation Loss: 1.866
24180
Training Epoch 126 --- Training Accuracy:  69.9%, Validation Accuracy:  47.1%,  Validation Loss: 1.861
24375
Training Epoch 127 --- Training Accuracy:  69.1%, Validation Accuracy:  48.1%,  Validation Loss: 1.863
24570
Training Epoch 128 --- Training Accuracy:  67.2%, Validation Accuracy:  45.2%,  Validation Loss: 1.872
24765
Training Epoch 129 --- Training Accuracy:  63.7%, Validation Accuracy:  46.8%,  Validation Loss: 1.870
24960
Training Epoch 130 --- Training Accuracy:  69.9%, Validation Accuracy:  46.7%,  Validation Loss: 1.878
25155
Training Epoch 131 --- Training Accuracy:  65.6%, Validation Accuracy:  46.5%,  Validation Loss: 1.860
25350
Training Epoch 132 --- Training Accuracy:  70.7%, Validation Accuracy:  46.5%,  Validation Loss: 1.869
25545
Training Epoch 133 --- Training Accuracy:  69.9%, Validation Accuracy:  47.4%,  Validation Loss: 1.862
25740
Training Epoch 134 --- Training Accuracy:  67.2%, Validation Accuracy:  47.6%,  Validation Loss: 1.874
25935
Training Epoch 135 --- Training Accuracy:  67.2%, Validation Accuracy:  46.6%,  Validation Loss: 1.878
26130
Training Epoch 136 --- Training Accuracy:  66.8%, Validation Accuracy:  46.0%,  Validation Loss: 1.872
26325
Training Epoch 137 --- Training Accuracy:  70.3%, Validation Accuracy:  48.2%,  Validation Loss: 1.869
26520
Training Epoch 138 --- Training Accuracy:  69.9%, Validation Accuracy:  47.0%,  Validation Loss: 1.861
26715
Training Epoch 139 --- Training Accuracy:  71.9%, Validation Accuracy:  46.9%,  Validation Loss: 1.869
26910
Training Epoch 140 --- Training Accuracy:  69.1%, Validation Accuracy:  48.4%,  Validation Loss: 1.876
27105
Training Epoch 141 --- Training Accuracy:  70.3%, Validation Accuracy:  46.3%,  Validation Loss: 1.867
27300
Training Epoch 142 --- Training Accuracy:  65.6%, Validation Accuracy:  48.6%,  Validation Loss: 1.868
27495
Training Epoch 143 --- Training Accuracy:  68.0%, Validation Accuracy:  47.4%,  Validation Loss: 1.874
27690
Training Epoch 144 --- Training Accuracy:  74.2%, Validation Accuracy:  49.5%,  Validation Loss: 1.861
27885
Training Epoch 145 --- Training Accuracy:  66.0%, Validation Accuracy:  47.5%,  Validation Loss: 1.866
28080
Training Epoch 146 --- Training Accuracy:  69.5%, Validation Accuracy:  47.8%,  Validation Loss: 1.861
28275
Training Epoch 147 --- Training Accuracy:  70.3%, Validation Accuracy:  47.9%,  Validation Loss: 1.859
28470
Training Epoch 148 --- Training Accuracy:  67.6%, Validation Accuracy:  47.2%,  Validation Loss: 1.864
28665
Training Epoch 149 --- Training Accuracy:  70.3%, Validation Accuracy:  47.0%,  Validation Loss: 1.863
28860
Training Epoch 150 --- Training Accuracy:  69.5%, Validation Accuracy:  48.1%,  Validation Loss: 1.866
29055
Training Epoch 151 --- Training Accuracy:  71.1%, Validation Accuracy:  48.6%,  Validation Loss: 1.860
29250
Training Epoch 152 --- Training Accuracy:  71.9%, Validation Accuracy:  47.0%,  Validation Loss: 1.864
29445
Training Epoch 153 --- Training Accuracy:  73.8%, Validation Accuracy:  47.4%,  Validation Loss: 1.864
29640
Training Epoch 154 --- Training Accuracy:  68.8%, Validation Accuracy:  46.7%,  Validation Loss: 1.881
29835
Training Epoch 155 --- Training Accuracy:  69.9%, Validation Accuracy:  44.7%,  Validation Loss: 1.883
30030
Training Epoch 156 --- Training Accuracy:  70.3%, Validation Accuracy:  46.3%,  Validation Loss: 1.873
30225
Training Epoch 157 --- Training Accuracy:  72.7%, Validation Accuracy:  46.7%,  Validation Loss: 1.886
30420
Training Epoch 158 --- Training Accuracy:  68.8%, Validation Accuracy:  46.0%,  Validation Loss: 1.878
30615
Training Epoch 159 --- Training Accuracy:  68.8%, Validation Accuracy:  49.8%,  Validation Loss: 1.867
30810
Training Epoch 160 --- Training Accuracy:  69.1%, Validation Accuracy:  47.8%,  Validation Loss: 1.879
31005
Training Epoch 161 --- Training Accuracy:  71.1%, Validation Accuracy:  49.4%,  Validation Loss: 1.864
31200
Training Epoch 162 --- Training Accuracy:  70.3%, Validation Accuracy:  47.4%,  Validation Loss: 1.876
31395
Training Epoch 163 --- Training Accuracy:  71.9%, Validation Accuracy:  48.6%,  Validation Loss: 1.876
31590
Training Epoch 164 --- Training Accuracy:  65.2%, Validation Accuracy:  45.3%,  Validation Loss: 1.885
31785
Training Epoch 165 --- Training Accuracy:  68.4%, Validation Accuracy:  48.1%,  Validation Loss: 1.882
31980
Training Epoch 166 --- Training Accuracy:  73.4%, Validation Accuracy:  48.6%,  Validation Loss: 1.868
32175
Training Epoch 167 --- Training Accuracy:  73.4%, Validation Accuracy:  47.8%,  Validation Loss: 1.871
32370
Training Epoch 168 --- Training Accuracy:  71.5%, Validation Accuracy:  46.4%,  Validation Loss: 1.869
32565
Training Epoch 169 --- Training Accuracy:  73.4%, Validation Accuracy:  47.4%,  Validation Loss: 1.873
32760
Training Epoch 170 --- Training Accuracy:  71.1%, Validation Accuracy:  47.2%,  Validation Loss: 1.878
32955
Training Epoch 171 --- Training Accuracy:  69.5%, Validation Accuracy:  47.7%,  Validation Loss: 1.869
33150
Training Epoch 172 --- Training Accuracy:  72.7%, Validation Accuracy:  47.5%,  Validation Loss: 1.876
33345
Training Epoch 173 --- Training Accuracy:  73.0%, Validation Accuracy:  48.4%,  Validation Loss: 1.867
33540
Training Epoch 174 --- Training Accuracy:  74.6%, Validation Accuracy:  46.5%,  Validation Loss: 1.872
33735
Training Epoch 175 --- Training Accuracy:  70.7%, Validation Accuracy:  48.8%,  Validation Loss: 1.867
33930
Training Epoch 176 --- Training Accuracy:  71.9%, Validation Accuracy:  48.6%,  Validation Loss: 1.869
34125
Training Epoch 177 --- Training Accuracy:  70.3%, Validation Accuracy:  46.8%,  Validation Loss: 1.877
34320
Training Epoch 178 --- Training Accuracy:  73.0%, Validation Accuracy:  48.1%,  Validation Loss: 1.860
34515
Training Epoch 179 --- Training Accuracy:  69.1%, Validation Accuracy:  47.0%,  Validation Loss: 1.861
34710
Training Epoch 180 --- Training Accuracy:  72.3%, Validation Accuracy:  47.5%,  Validation Loss: 1.875
34905
Training Epoch 181 --- Training Accuracy:  73.0%, Validation Accuracy:  49.3%,  Validation Loss: 1.868
35100
Training Epoch 182 --- Training Accuracy:  70.7%, Validation Accuracy:  47.9%,  Validation Loss: 1.882
35295
Training Epoch 183 --- Training Accuracy:  67.6%, Validation Accuracy:  47.5%,  Validation Loss: 1.872
35490
Training Epoch 184 --- Training Accuracy:  68.0%, Validation Accuracy:  48.8%,  Validation Loss: 1.866
35685
Training Epoch 185 --- Training Accuracy:  73.4%, Validation Accuracy:  47.7%,  Validation Loss: 1.870
35880
Training Epoch 186 --- Training Accuracy:  71.5%, Validation Accuracy:  48.8%,  Validation Loss: 1.863
36075
Training Epoch 187 --- Training Accuracy:  71.5%, Validation Accuracy:  48.7%,  Validation Loss: 1.868
36270
Training Epoch 188 --- Training Accuracy:  69.9%, Validation Accuracy:  48.1%,  Validation Loss: 1.882
36465
Training Epoch 189 --- Training Accuracy:  68.8%, Validation Accuracy:  47.8%,  Validation Loss: 1.866
36660
Training Epoch 190 --- Training Accuracy:  76.6%, Validation Accuracy:  48.8%,  Validation Loss: 1.871
36855
Training Epoch 191 --- Training Accuracy:  74.2%, Validation Accuracy:  46.5%,  Validation Loss: 1.877
37050
Training Epoch 192 --- Training Accuracy:  69.5%, Validation Accuracy:  49.1%,  Validation Loss: 1.882
37245
Training Epoch 193 --- Training Accuracy:  69.5%, Validation Accuracy:  48.1%,  Validation Loss: 1.870
37440
Training Epoch 194 --- Training Accuracy:  75.4%, Validation Accuracy:  49.3%,  Validation Loss: 1.872
37635
Training Epoch 195 --- Training Accuracy:  70.3%, Validation Accuracy:  47.5%,  Validation Loss: 1.870
37830
Training Epoch 196 --- Training Accuracy:  74.6%, Validation Accuracy:  48.1%,  Validation Loss: 1.861
38025
Training Epoch 197 --- Training Accuracy:  70.3%, Validation Accuracy:  48.2%,  Validation Loss: 1.884
38220
Training Epoch 198 --- Training Accuracy:  75.4%, Validation Accuracy:  48.1%,  Validation Loss: 1.880
38415
Training Epoch 199 --- Training Accuracy:  69.1%, Validation Accuracy:  46.3%,  Validation Loss: 1.879
38610
Training Epoch 200 --- Training Accuracy:  66.8%, Validation Accuracy:  45.8%,  Validation Loss: 1.876
38805
Training Epoch 201 --- Training Accuracy:  69.5%, Validation Accuracy:  47.5%,  Validation Loss: 1.873
39000
Training Epoch 202 --- Training Accuracy:  71.9%, Validation Accuracy:  47.2%,  Validation Loss: 1.866
39195
Training Epoch 203 --- Training Accuracy:  74.2%, Validation Accuracy:  48.4%,  Validation Loss: 1.868
39390
Training Epoch 204 --- Training Accuracy:  73.4%, Validation Accuracy:  49.0%,  Validation Loss: 1.875
39585
Training Epoch 205 --- Training Accuracy:  72.3%, Validation Accuracy:  48.1%,  Validation Loss: 1.868
39780
Training Epoch 206 --- Training Accuracy:  68.4%, Validation Accuracy:  47.4%,  Validation Loss: 1.878
39975
Training Epoch 207 --- Training Accuracy:  71.5%, Validation Accuracy:  46.5%,  Validation Loss: 1.867
40170
Training Epoch 208 --- Training Accuracy:  69.1%, Validation Accuracy:  47.2%,  Validation Loss: 1.877
40365
Training Epoch 209 --- Training Accuracy:  71.9%, Validation Accuracy:  48.2%,  Validation Loss: 1.873
40560
Training Epoch 210 --- Training Accuracy:  71.5%, Validation Accuracy:  46.5%,  Validation Loss: 1.873
40755
Training Epoch 211 --- Training Accuracy:  70.3%, Validation Accuracy:  48.5%,  Validation Loss: 1.869
40950
Training Epoch 212 --- Training Accuracy:  70.3%, Validation Accuracy:  47.7%,  Validation Loss: 1.863
41145
Training Epoch 213 --- Training Accuracy:  76.6%, Validation Accuracy:  48.9%,  Validation Loss: 1.867
41340
Training Epoch 214 --- Training Accuracy:  74.2%, Validation Accuracy:  48.1%,  Validation Loss: 1.868
41535
Training Epoch 215 --- Training Accuracy:  71.5%, Validation Accuracy:  48.1%,  Validation Loss: 1.865
41730
Training Epoch 216 --- Training Accuracy:  71.1%, Validation Accuracy:  47.7%,  Validation Loss: 1.869
41925
Training Epoch 217 --- Training Accuracy:  66.4%, Validation Accuracy:  45.4%,  Validation Loss: 1.892
42120
Training Epoch 218 --- Training Accuracy:  75.4%, Validation Accuracy:  47.4%,  Validation Loss: 1.869
42315
Training Epoch 219 --- Training Accuracy:  75.4%, Validation Accuracy:  48.2%,  Validation Loss: 1.875
42510
Training Epoch 220 --- Training Accuracy:  77.3%, Validation Accuracy:  48.0%,  Validation Loss: 1.885
42705
Training Epoch 221 --- Training Accuracy:  75.0%, Validation Accuracy:  49.2%,  Validation Loss: 1.865
42900
Training Epoch 222 --- Training Accuracy:  71.9%, Validation Accuracy:  45.6%,  Validation Loss: 1.869
43095
Training Epoch 223 --- Training Accuracy:  73.0%, Validation Accuracy:  48.0%,  Validation Loss: 1.863
43290
Training Epoch 224 --- Training Accuracy:  76.2%, Validation Accuracy:  46.9%,  Validation Loss: 1.875
43485
Training Epoch 225 --- Training Accuracy:  75.8%, Validation Accuracy:  47.7%,  Validation Loss: 1.864
43680
Training Epoch 226 --- Training Accuracy:  71.9%, Validation Accuracy:  47.5%,  Validation Loss: 1.879
43875
Training Epoch 227 --- Training Accuracy:  75.0%, Validation Accuracy:  47.7%,  Validation Loss: 1.876
44070
Training Epoch 228 --- Training Accuracy:  70.7%, Validation Accuracy:  46.6%,  Validation Loss: 1.865
44265
Training Epoch 229 --- Training Accuracy:  75.8%, Validation Accuracy:  47.7%,  Validation Loss: 1.865
44460
Training Epoch 230 --- Training Accuracy:  77.7%, Validation Accuracy:  46.1%,  Validation Loss: 1.870
44655
Training Epoch 231 --- Training Accuracy:  71.5%, Validation Accuracy:  47.8%,  Validation Loss: 1.878
44850
Training Epoch 232 --- Training Accuracy:  75.4%, Validation Accuracy:  48.1%,  Validation Loss: 1.867
45045
Training Epoch 233 --- Training Accuracy:  79.7%, Validation Accuracy:  49.1%,  Validation Loss: 1.870
45240
Training Epoch 234 --- Training Accuracy:  73.0%, Validation Accuracy:  48.3%,  Validation Loss: 1.871
45435
Training Epoch 235 --- Training Accuracy:  75.8%, Validation Accuracy:  48.1%,  Validation Loss: 1.873
45630
Training Epoch 236 --- Training Accuracy:  75.8%, Validation Accuracy:  48.0%,  Validation Loss: 1.863
45825
Training Epoch 237 --- Training Accuracy:  73.0%, Validation Accuracy:  47.8%,  Validation Loss: 1.868
46020
Training Epoch 238 --- Training Accuracy:  71.1%, Validation Accuracy:  47.5%,  Validation Loss: 1.873
46215
Training Epoch 239 --- Training Accuracy:  74.2%, Validation Accuracy:  48.3%,  Validation Loss: 1.867
46410
Training Epoch 240 --- Training Accuracy:  77.7%, Validation Accuracy:  48.1%,  Validation Loss: 1.877
46605
Training Epoch 241 --- Training Accuracy:  74.6%, Validation Accuracy:  49.3%,  Validation Loss: 1.864
46800
Training Epoch 242 --- Training Accuracy:  76.6%, Validation Accuracy:  48.2%,  Validation Loss: 1.864
46995
Training Epoch 243 --- Training Accuracy:  73.8%, Validation Accuracy:  48.6%,  Validation Loss: 1.861
47190
Training Epoch 244 --- Training Accuracy:  70.7%, Validation Accuracy:  47.9%,  Validation Loss: 1.874
47385
Training Epoch 245 --- Training Accuracy:  76.6%, Validation Accuracy:  49.4%,  Validation Loss: 1.864
47580
Training Epoch 246 --- Training Accuracy:  75.0%, Validation Accuracy:  45.6%,  Validation Loss: 1.888
47775
Training Epoch 247 --- Training Accuracy:  72.7%, Validation Accuracy:  48.9%,  Validation Loss: 1.874
47970
Training Epoch 248 --- Training Accuracy:  76.2%, Validation Accuracy:  47.9%,  Validation Loss: 1.867
48165
Training Epoch 249 --- Training Accuracy:  73.0%, Validation Accuracy:  47.2%,  Validation Loss: 1.889
48360
Training Epoch 250 --- Training Accuracy:  79.7%, Validation Accuracy:  49.2%,  Validation Loss: 1.885
48555
Training Epoch 251 --- Training Accuracy:  70.3%, Validation Accuracy:  46.0%,  Validation Loss: 1.874
48750
Training Epoch 252 --- Training Accuracy:  69.9%, Validation Accuracy:  48.4%,  Validation Loss: 1.885
48945
Training Epoch 253 --- Training Accuracy:  75.8%, Validation Accuracy:  48.2%,  Validation Loss: 1.889
49140
Training Epoch 254 --- Training Accuracy:  71.5%, Validation Accuracy:  47.8%,  Validation Loss: 1.871
49335
Training Epoch 255 --- Training Accuracy:  75.4%, Validation Accuracy:  47.2%,  Validation Loss: 1.881
49530
Training Epoch 256 --- Training Accuracy:  77.3%, Validation Accuracy:  47.7%,  Validation Loss: 1.883
49725
Training Epoch 257 --- Training Accuracy:  74.2%, Validation Accuracy:  48.2%,  Validation Loss: 1.867
49920
Training Epoch 258 --- Training Accuracy:  74.6%, Validation Accuracy:  46.5%,  Validation Loss: 1.887
50115
Training Epoch 259 --- Training Accuracy:  77.7%, Validation Accuracy:  48.9%,  Validation Loss: 1.877
50310
Training Epoch 260 --- Training Accuracy:  75.8%, Validation Accuracy:  48.9%,  Validation Loss: 1.862
50505
Training Epoch 261 --- Training Accuracy:  74.2%, Validation Accuracy:  48.8%,  Validation Loss: 1.877
50700
Training Epoch 262 --- Training Accuracy:  73.8%, Validation Accuracy:  47.2%,  Validation Loss: 1.867
50895
Training Epoch 263 --- Training Accuracy:  77.0%, Validation Accuracy:  47.9%,  Validation Loss: 1.870
51090
Training Epoch 264 --- Training Accuracy:  75.0%, Validation Accuracy:  47.5%,  Validation Loss: 1.883
51285
Training Epoch 265 --- Training Accuracy:  75.8%, Validation Accuracy:  48.2%,  Validation Loss: 1.880
51480
Training Epoch 266 --- Training Accuracy:  73.4%, Validation Accuracy:  47.0%,  Validation Loss: 1.884
51675
Training Epoch 267 --- Training Accuracy:  72.7%, Validation Accuracy:  47.0%,  Validation Loss: 1.874
51870
Training Epoch 268 --- Training Accuracy:  73.8%, Validation Accuracy:  46.8%,  Validation Loss: 1.873
52065
Training Epoch 269 --- Training Accuracy:  75.8%, Validation Accuracy:  47.6%,  Validation Loss: 1.866
52260
Training Epoch 270 --- Training Accuracy:  74.6%, Validation Accuracy:  47.4%,  Validation Loss: 1.876
52455
Training Epoch 271 --- Training Accuracy:  80.1%, Validation Accuracy:  48.6%,  Validation Loss: 1.877
52650
Training Epoch 272 --- Training Accuracy:  74.6%, Validation Accuracy:  47.2%,  Validation Loss: 1.875
52845
Training Epoch 273 --- Training Accuracy:  73.8%, Validation Accuracy:  47.4%,  Validation Loss: 1.880
53040
Training Epoch 274 --- Training Accuracy:  75.8%, Validation Accuracy:  47.2%,  Validation Loss: 1.872
53235
Training Epoch 275 --- Training Accuracy:  76.6%, Validation Accuracy:  49.3%,  Validation Loss: 1.866
53430
Training Epoch 276 --- Training Accuracy:  72.3%, Validation Accuracy:  49.6%,  Validation Loss: 1.879
53625
Training Epoch 277 --- Training Accuracy:  76.2%, Validation Accuracy:  49.9%,  Validation Loss: 1.870
53820
Training Epoch 278 --- Training Accuracy:  75.4%, Validation Accuracy:  48.2%,  Validation Loss: 1.867
54015
Training Epoch 279 --- Training Accuracy:  75.8%, Validation Accuracy:  48.6%,  Validation Loss: 1.862
54210
Training Epoch 280 --- Training Accuracy:  75.8%, Validation Accuracy:  46.1%,  Validation Loss: 1.889
54405
Training Epoch 281 --- Training Accuracy:  72.7%, Validation Accuracy:  45.8%,  Validation Loss: 1.878
54600
Training Epoch 282 --- Training Accuracy:  75.4%, Validation Accuracy:  48.4%,  Validation Loss: 1.896
54795
Training Epoch 283 --- Training Accuracy:  75.4%, Validation Accuracy:  48.6%,  Validation Loss: 1.867
54990
Training Epoch 284 --- Training Accuracy:  73.4%, Validation Accuracy:  49.1%,  Validation Loss: 1.884
55185
Training Epoch 285 --- Training Accuracy:  71.5%, Validation Accuracy:  47.7%,  Validation Loss: 1.868
55380
Training Epoch 286 --- Training Accuracy:  74.6%, Validation Accuracy:  46.3%,  Validation Loss: 1.888
55575
Training Epoch 287 --- Training Accuracy:  75.4%, Validation Accuracy:  47.2%,  Validation Loss: 1.879
55770
Training Epoch 288 --- Training Accuracy:  73.8%, Validation Accuracy:  46.2%,  Validation Loss: 1.886
55965
Training Epoch 289 --- Training Accuracy:  75.0%, Validation Accuracy:  47.1%,  Validation Loss: 1.873
56160
Training Epoch 290 --- Training Accuracy:  73.8%, Validation Accuracy:  46.1%,  Validation Loss: 1.900
56355
Training Epoch 291 --- Training Accuracy:  78.5%, Validation Accuracy:  48.4%,  Validation Loss: 1.878
56550
Training Epoch 292 --- Training Accuracy:  70.7%, Validation Accuracy:  46.4%,  Validation Loss: 1.880
56745
Training Epoch 293 --- Training Accuracy:  75.0%, Validation Accuracy:  48.4%,  Validation Loss: 1.868
56940
Training Ep